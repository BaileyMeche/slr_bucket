{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLR summary pipeline\n",
    "\n",
    "Run-all reproducible pipeline for daily_long event-study analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"event_dates\": [\n",
      "    \"2020-04-01\",\n",
      "    \"2021-03-19\",\n",
      "    \"2021-03-31\"\n",
      "  ],\n",
      "  \"windows\": [\n",
      "    3,\n",
      "    5,\n",
      "    10\n",
      "  ],\n",
      "  \"event_bins\": [\n",
      "    [\n",
      "      -60,\n",
      "      -41\n",
      "    ],\n",
      "    [\n",
      "      -40,\n",
      "      -21\n",
      "    ],\n",
      "    [\n",
      "      -20,\n",
      "      -1\n",
      "    ],\n",
      "    [\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      20\n",
      "    ],\n",
      "    [\n",
      "      21,\n",
      "      40\n",
      "    ],\n",
      "    [\n",
      "      41,\n",
      "      60\n",
      "    ]\n",
      "  ],\n",
      "  \"dependent_series\": null,\n",
      "  \"tenor_subset\": null,\n",
      "  \"total_controls\": [],\n",
      "  \"direct_controls\": [\n",
      "    \"sofr\",\n",
      "    \"tgcr\",\n",
      "    \"bgcr\"\n",
      "  ],\n",
      "  \"hac_lags\": 5,\n",
      "  \"bootstrap_reps\": 200,\n",
      "  \"bootstrap_block_size\": 5,\n",
      "  \"random_seed\": 42,\n",
      "  \"output_root\": \"outputs/summary_pipeline\",\n",
      "  \"cache_root\": \"outputs/cache\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from slr_bucket.config import PipelineConfig\n",
    "\n",
    "# CONFIG\n",
    "CONFIG = PipelineConfig(\n",
    "    event_dates=['2020-04-01', '2021-03-19', '2021-03-31'],\n",
    "    windows=[3, 5, 10],\n",
    "    event_bins=[(-60,-41),(-40,-21),(-20,-1),(0,0),(1,20),(21,40),(41,60)],\n",
    "    dependent_series=None,\n",
    "    tenor_subset=None,\n",
    "    total_controls=[],\n",
    "    direct_controls=['sofr', 'tgcr', 'bgcr'],\n",
    "    hac_lags=5,\n",
    "    bootstrap_reps=200,\n",
    "    bootstrap_block_size=5,\n",
    "    random_seed=42,\n",
    "    output_root='outputs/summary_pipeline',\n",
    "    cache_root='outputs/cache',\n",
    ")\n",
    "REPO_ROOT = Path().cwd().resolve().parent\n",
    "SRC_DIR = REPO_ROOT / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "DATA_DIR = REPO_ROOT / 'data'\n",
    "print(json.dumps(CONFIG.__dict__, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inputs and construction of daily_long\n",
    "\n",
    "This section discovers local files, builds a data catalog, validates `daily_long`, and persists deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 11:12:21,954 INFO summary_pipeline - catalog rows=25\n",
      "2026-02-26 11:12:22,052 INFO summary_pipeline - funding mapping: {'ofr': 'C:\\\\Users\\\\Owner\\\\Box\\\\Winter26\\\\slr_bucket\\\\data\\\\event_inputs\\\\primary_dealer_stats_ofr_stfm_nypd_long.csv', 'repo': 'C:\\\\Users\\\\Owner\\\\Box\\\\Winter26\\\\slr_bucket\\\\data\\\\event_inputs\\\\repo_rates_combined.csv'}\n",
      "2026-02-26 11:12:22,130 INFO summary_pipeline - daily_long rows=14 saved=C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\cache\\daily_long_f562fdf488e4.parquet\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from slr_bucket.io import build_data_catalog, find_daily_long, discover_funding_series\n",
    "from slr_bucket.pipeline import prepare_run_dirs, refresh_latest, setup_logging, write_catalog_outputs, write_run_readme\n",
    "from slr_bucket.validation import validate_daily_long\n",
    "\n",
    "run_dirs = prepare_run_dirs(REPO_ROOT, CONFIG)\n",
    "setup_logging(run_dirs['logs'] / 'pipeline.log')\n",
    "logger = logging.getLogger('summary_pipeline')\n",
    "\n",
    "catalog = build_data_catalog(DATA_DIR)\n",
    "write_catalog_outputs(catalog, run_dirs['data'])\n",
    "logger.info('catalog rows=%s', len(catalog))\n",
    "\n",
    "funding_mapping = discover_funding_series(DATA_DIR)\n",
    "logger.info('funding mapping: %s', funding_mapping)\n",
    "\n",
    "daily_long = validate_daily_long(find_daily_long(DATA_DIR))\n",
    "cache_dir = REPO_ROOT / CONFIG.cache_root\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "cache_path = cache_dir / f'daily_long_{CONFIG.to_hash()}.parquet'\n",
    "daily_long.to_parquet(cache_path, index=False)\n",
    "logger.info('daily_long rows=%s saved=%s', len(daily_long), cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 11:12:22,149 INFO summary_pipeline - dependent series: ['wedge']\n",
      "2026-02-26 11:12:22,152 INFO summary_pipeline - tenors: ['2y']\n"
     ]
    }
   ],
   "source": [
    "pivot = daily_long.pivot_table(index=['date','tenor'], columns='series', values='value', aggfunc='last').reset_index()\n",
    "if CONFIG.tenor_subset:\n",
    "    pivot = pivot[pivot['tenor'].isin(CONFIG.tenor_subset)]\n",
    "\n",
    "series_candidates = [c for c in pivot.columns if c not in {'date', 'tenor'}]\n",
    "if CONFIG.dependent_series:\n",
    "    dep_series = [s for s in CONFIG.dependent_series if s in series_candidates]\n",
    "else:\n",
    "    # dep_series = series_candidates[: min(len(series_candidates), 5)]\n",
    "    control_set = set(CONFIG.total_controls or []) | set(CONFIG.direct_controls or [])\n",
    "    auto_candidates = [c for c in series_candidates if c not in control_set]\n",
    "\n",
    "    dep_series = auto_candidates[: min(len(auto_candidates), 5)] if auto_candidates else series_candidates[:5]\n",
    "\n",
    "if not dep_series:\n",
    "    raise ValueError('No dependent series selected. Check CONFIG.dependent_series or daily_long series availability.')\n",
    "\n",
    "logger.info('dependent series: %s', dep_series)\n",
    "logger.info('tenors: %s', sorted(pivot['tenor'].dropna().astype(str).unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econometric designs\n",
    "\n",
    "- Windowed jumps: pre/post mean-shift regression with HAC SE and bootstrap robustness.\n",
    "- Event-study bins: total-effect and direct-effect specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_1924\\4144296982.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>window</th>\n",
       "      <th>spec</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>bootstrap_se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>10</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date tenor series  window    spec  estimate  se  bootstrap_se  \\\n",
       "0  2020-04-01    2y  wedge       3   total       NaN NaN           NaN   \n",
       "1  2020-04-01    2y  wedge       3  direct       NaN NaN           NaN   \n",
       "2  2020-04-01    2y  wedge       5   total       NaN NaN           NaN   \n",
       "3  2020-04-01    2y  wedge       5  direct       NaN NaN           NaN   \n",
       "4  2020-04-01    2y  wedge      10   total       NaN NaN           NaN   \n",
       "\n",
       "   ci_low  ci_high  n  \n",
       "0     NaN      NaN  4  \n",
       "1     NaN      NaN  4  \n",
       "2     NaN      NaN  5  \n",
       "3     NaN      NaN  5  \n",
       "4     NaN      NaN  7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from slr_bucket.econometrics.event_study import jump_estimator, block_bootstrap_jump, event_study_regression\n",
    "from slr_bucket.plotting.plots import plot_series_with_events, plot_event_paths\n",
    "\n",
    "jump_rows = []\n",
    "bin_rows = []\n",
    "for tenor, tdf in pivot.groupby('tenor'):\n",
    "    tdf = tdf.sort_values('date').copy()\n",
    "    for y in dep_series:\n",
    "        if y not in tdf.columns:\n",
    "            continue\n",
    "        direct_controls = [c for c in (CONFIG.direct_controls or []) if (c in tdf.columns and c != y)]\n",
    "        sub_cols = ['date', y] + direct_controls\n",
    "        # preserve order, remove duplicates\n",
    "        seen = set()\n",
    "        sub_cols = [c for c in sub_cols if not (c in seen or seen.add(c))]\n",
    "        sub = tdf[sub_cols].copy()\n",
    "        sub = sub.dropna(subset=[y])\n",
    "        if sub.empty:\n",
    "            warnings.warn(f'No data for {tenor}-{y}')\n",
    "            continue\n",
    "\n",
    "        plot_series_with_events(sub.rename(columns={y: 'dep'}), 'dep', CONFIG.event_dates, f'{tenor} {y}', run_dirs['figures'] / f'series_{tenor}_{y}.png')\n",
    "\n",
    "        for event in CONFIG.event_dates:\n",
    "            for w in CONFIG.windows:\n",
    "                est, se, n = jump_estimator(sub, y, event, w, controls=None, hac_lags=CONFIG.hac_lags)\n",
    "                bse = block_bootstrap_jump(sub, y, event, w, controls=None, reps=CONFIG.bootstrap_reps, block_size=CONFIG.bootstrap_block_size, seed=CONFIG.random_seed)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'total', 'estimate': est, 'se': se, 'bootstrap_se': bse, 'ci_low': est-1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'ci_high': est+1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'n': n})\n",
    "\n",
    "                est_d, se_d, n_d = jump_estimator(sub, y, event, w, controls=direct_controls, hac_lags=CONFIG.hac_lags)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'direct', 'estimate': est_d, 'se': se_d, 'bootstrap_se': np.nan, 'ci_low': est_d-1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'ci_high': est_d+1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'n': n_d})\n",
    "\n",
    "            for spec_name, controls in [('total', None), ('direct', direct_controls)]:\n",
    "                bins_df = event_study_regression(sub, y, event, CONFIG.event_bins, controls=controls, hac_lags=CONFIG.hac_lags)\n",
    "                bins_df['event_date'] = event\n",
    "                bins_df['tenor'] = tenor\n",
    "                bins_df['series'] = y\n",
    "                bins_df['spec'] = spec_name\n",
    "                bin_rows.append(bins_df)\n",
    "                plot_event_paths(bins_df, f'{tenor} {y} {event} {spec_name}', run_dirs['figures'] / f'event_path_{tenor}_{y}_{event}_{spec_name}.png')\n",
    "\n",
    "jump_table = pd.DataFrame(jump_rows)\n",
    "bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n",
    "\n",
    "jump_table.to_csv(run_dirs['tables'] / 'jump_estimates.csv', index=False)\n",
    "if not bin_table.empty:\n",
    "    bin_table.to_csv(run_dirs['tables'] / 'event_study_bins.csv', index=False)\n",
    "\n",
    "jump_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9e32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_1924\\4127238930.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>window</th>\n",
       "      <th>spec</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>bootstrap_se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>10</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date tenor series  window    spec  estimate  se  bootstrap_se  \\\n",
       "0  2020-04-01    2y  wedge       3   total       NaN NaN           NaN   \n",
       "1  2020-04-01    2y  wedge       3  direct       NaN NaN           NaN   \n",
       "2  2020-04-01    2y  wedge       5   total       NaN NaN           NaN   \n",
       "3  2020-04-01    2y  wedge       5  direct       NaN NaN           NaN   \n",
       "4  2020-04-01    2y  wedge      10   total       NaN NaN           NaN   \n",
       "\n",
       "   ci_low  ci_high  n  \n",
       "0     NaN      NaN  4  \n",
       "1     NaN      NaN  4  \n",
       "2     NaN      NaN  5  \n",
       "3     NaN      NaN  5  \n",
       "4     NaN      NaN  7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from slr_bucket.econometrics.event_study import jump_estimator, block_bootstrap_jump, event_study_regression\n",
    "from slr_bucket.plotting.plots import plot_series_with_events, plot_event_paths\n",
    "\n",
    "jump_rows = []\n",
    "bin_rows = []\n",
    "for tenor, tdf in pivot.groupby('tenor'):\n",
    "    tdf = tdf.sort_values('date').copy()\n",
    "    for y in dep_series:\n",
    "        if y not in tdf.columns:\n",
    "            continue\n",
    "        # sub = tdf[['date', y] + [c for c in CONFIG.direct_controls if c in tdf.columns]].copy()\n",
    "        \n",
    "        sub = sub.dropna(subset=[y])\n",
    "        if sub.empty:\n",
    "            warnings.warn(f'No data for {tenor}-{y}')\n",
    "            continue\n",
    "\n",
    "        plot_series_with_events(sub.rename(columns={y: 'dep'}), 'dep', CONFIG.event_dates, f'{tenor} {y}', run_dirs['figures'] / f'series_{tenor}_{y}.png')\n",
    "\n",
    "        for event in CONFIG.event_dates:\n",
    "            for w in CONFIG.windows:\n",
    "                est, se, n = jump_estimator(sub, y, event, w, controls=None, hac_lags=CONFIG.hac_lags)\n",
    "                bse = block_bootstrap_jump(sub, y, event, w, controls=None, reps=CONFIG.bootstrap_reps, block_size=CONFIG.bootstrap_block_size, seed=CONFIG.random_seed)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'total', 'estimate': est, 'se': se, 'bootstrap_se': bse, 'ci_low': est-1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'ci_high': est+1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'n': n})\n",
    "\n",
    "                est_d, se_d, n_d = jump_estimator(sub, y, event, w, controls=CONFIG.direct_controls, hac_lags=CONFIG.hac_lags)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'direct', 'estimate': est_d, 'se': se_d, 'bootstrap_se': np.nan, 'ci_low': est_d-1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'ci_high': est_d+1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'n': n_d})\n",
    "\n",
    "            for spec_name, controls in [('total', None), ('direct', CONFIG.direct_controls)]:\n",
    "                bins_df = event_study_regression(sub, y, event, CONFIG.event_bins, controls=controls, hac_lags=CONFIG.hac_lags)\n",
    "                bins_df['event_date'] = event\n",
    "                bins_df['tenor'] = tenor\n",
    "                bins_df['series'] = y\n",
    "                bins_df['spec'] = spec_name\n",
    "                bin_rows.append(bins_df)\n",
    "                plot_event_paths(bins_df, f'{tenor} {y} {event} {spec_name}', run_dirs['figures'] / f'event_path_{tenor}_{y}_{event}_{spec_name}.png')\n",
    "\n",
    "jump_table = pd.DataFrame(jump_rows)\n",
    "bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n",
    "\n",
    "jump_table.to_csv(run_dirs['tables'] / 'jump_estimates.csv', index=False)\n",
    "if not bin_table.empty:\n",
    "    bin_table.to_csv(run_dirs['tables'] / 'event_study_bins.csv', index=False)\n",
    "\n",
    "jump_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b1382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_1924\\4127238930.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>window</th>\n",
       "      <th>spec</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>bootstrap_se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>10</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date tenor series  window    spec  estimate  se  bootstrap_se  \\\n",
       "0  2020-04-01    2y  wedge       3   total       NaN NaN           NaN   \n",
       "1  2020-04-01    2y  wedge       3  direct       NaN NaN           NaN   \n",
       "2  2020-04-01    2y  wedge       5   total       NaN NaN           NaN   \n",
       "3  2020-04-01    2y  wedge       5  direct       NaN NaN           NaN   \n",
       "4  2020-04-01    2y  wedge      10   total       NaN NaN           NaN   \n",
       "\n",
       "   ci_low  ci_high  n  \n",
       "0     NaN      NaN  4  \n",
       "1     NaN      NaN  4  \n",
       "2     NaN      NaN  5  \n",
       "3     NaN      NaN  5  \n",
       "4     NaN      NaN  7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from slr_bucket.econometrics.event_study import jump_estimator, block_bootstrap_jump, event_study_regression\n",
    "from slr_bucket.plotting.plots import plot_series_with_events, plot_event_paths\n",
    "\n",
    "jump_rows = []\n",
    "bin_rows = []\n",
    "for tenor, tdf in pivot.groupby('tenor'):\n",
    "    tdf = tdf.sort_values('date').copy()\n",
    "    for y in dep_series:\n",
    "        if y not in tdf.columns:\n",
    "            continue\n",
    "        # sub = tdf[['date', y] + [c for c in CONFIG.direct_controls if c in tdf.columns]].copy()\n",
    "        \n",
    "        sub = sub.dropna(subset=[y])\n",
    "        if sub.empty:\n",
    "            warnings.warn(f'No data for {tenor}-{y}')\n",
    "            continue\n",
    "\n",
    "        plot_series_with_events(sub.rename(columns={y: 'dep'}), 'dep', CONFIG.event_dates, f'{tenor} {y}', run_dirs['figures'] / f'series_{tenor}_{y}.png')\n",
    "\n",
    "        for event in CONFIG.event_dates:\n",
    "            for w in CONFIG.windows:\n",
    "                est, se, n = jump_estimator(sub, y, event, w, controls=None, hac_lags=CONFIG.hac_lags)\n",
    "                bse = block_bootstrap_jump(sub, y, event, w, controls=None, reps=CONFIG.bootstrap_reps, block_size=CONFIG.bootstrap_block_size, seed=CONFIG.random_seed)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'total', 'estimate': est, 'se': se, 'bootstrap_se': bse, 'ci_low': est-1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'ci_high': est+1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'n': n})\n",
    "\n",
    "                est_d, se_d, n_d = jump_estimator(sub, y, event, w, controls=CONFIG.direct_controls, hac_lags=CONFIG.hac_lags)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'direct', 'estimate': est_d, 'se': se_d, 'bootstrap_se': np.nan, 'ci_low': est_d-1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'ci_high': est_d+1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'n': n_d})\n",
    "\n",
    "            for spec_name, controls in [('total', None), ('direct', CONFIG.direct_controls)]:\n",
    "                bins_df = event_study_regression(sub, y, event, CONFIG.event_bins, controls=controls, hac_lags=CONFIG.hac_lags)\n",
    "                bins_df['event_date'] = event\n",
    "                bins_df['tenor'] = tenor\n",
    "                bins_df['series'] = y\n",
    "                bins_df['spec'] = spec_name\n",
    "                bin_rows.append(bins_df)\n",
    "                plot_event_paths(bins_df, f'{tenor} {y} {event} {spec_name}', run_dirs['figures'] / f'event_path_{tenor}_{y}_{event}_{spec_name}.png')\n",
    "\n",
    "jump_table = pd.DataFrame(jump_rows)\n",
    "bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n",
    "\n",
    "jump_table.to_csv(run_dirs['tables'] / 'jump_estimates.csv', index=False)\n",
    "if not bin_table.empty:\n",
    "    bin_table.to_csv(run_dirs['tables'] / 'event_study_bins.csv', index=False)\n",
    "\n",
    "jump_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility + how to rerun\n",
    "\n",
    "- Run all cells in Jupyter, or execute `python scripts/run_notebook.py`.\n",
    "- Outputs are timestamped + config-hashed, and `latest/` is refreshed each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\summary_pipeline\\20260226_171216_f562fdf488e4\n",
      "Latest: C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\summary_pipeline\\latest\n",
      "Latest refreshed: C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\summary_pipeline\\latest\n"
     ]
    }
   ],
   "source": [
    "notes = (\n",
    "    f\"Processed {len(daily_long)} daily_long rows across {daily_long['tenor'].nunique()} tenors and \"\n",
    "    f\"{daily_long['series'].nunique()} series.\"\n",
    ")\n",
    "write_run_readme(run_dirs['run'], CONFIG, notes)\n",
    "print('Run dir:', run_dirs['run'])\n",
    "print('Latest:', REPO_ROOT / CONFIG.output_root / 'latest')\n",
    "latest_dir = refresh_latest(REPO_ROOT, CONFIG, run_dirs['run'])\n",
    "print('Latest refreshed:', latest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "\n",
    "Basic diagnostics for missingness and sample support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2y</td>\n",
       "      <td>sofr</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>7</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.039158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tenor series  count  mean       std\n",
       "0    2y   sofr      7  0.01  0.000000\n",
       "1    2y  wedge      7  0.14  0.039158"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity = (\n",
    "    daily_long.groupby(['tenor','series'])['value']\n",
    "    .agg(['count','mean','std'])\n",
    "    .reset_index()\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "sanity.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
