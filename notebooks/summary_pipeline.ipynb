{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLR summary pipeline\n",
    "\n",
    "Run-all reproducible pipeline for daily_long event-study analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from slr_bucket.config import PipelineConfig\n",
    "\n",
    "# CONFIG\n",
    "CONFIG = PipelineConfig(\n",
    "    event_dates=['2020-04-01', '2021-03-19', '2021-03-31'],\n",
    "    windows=[3, 5, 10],\n",
    "    event_bins=[(-60,-41),(-40,-21),(-20,-1),(0,0),(1,20),(21,40),(41,60)],\n",
    "    dependent_series=None,\n",
    "    tenor_subset=None,\n",
    "    total_controls=[],\n",
    "    direct_controls=['sofr', 'tgcr', 'bgcr'],\n",
    "    hac_lags=5,\n",
    "    bootstrap_reps=200,\n",
    "    bootstrap_block_size=5,\n",
    "    random_seed=42,\n",
    "    output_root='outputs/summary_pipeline',\n",
    "    cache_root='outputs/cache',\n",
    ")\n",
    "REPO_ROOT = Path().cwd().resolve().parent\n",
    "SRC_DIR = REPO_ROOT / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "DATA_DIR = REPO_ROOT / 'data'\n",
    "print(json.dumps(CONFIG.__dict__, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inputs and construction of daily_long\n",
    "\n",
    "This section discovers local files, builds a data catalog, validates `daily_long`, and persists deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 10:50:06,882 INFO summary_pipeline - catalog rows=25\n",
      "2026-02-26 10:50:06,942 INFO summary_pipeline - funding mapping: {'ofr': 'C:\\\\Users\\\\Owner\\\\Box\\\\Winter26\\\\slr_bucket\\\\data\\\\event_inputs\\\\primary_dealer_stats_ofr_stfm_nypd_long.csv', 'repo': 'C:\\\\Users\\\\Owner\\\\Box\\\\Winter26\\\\slr_bucket\\\\data\\\\event_inputs\\\\repo_rates_combined.csv'}\n",
      "2026-02-26 10:50:07,001 INFO summary_pipeline - daily_long rows=14 saved=C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\cache\\daily_long_f562fdf488e4.parquet\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from slr_bucket.io import build_data_catalog, find_daily_long, discover_funding_series\n",
    "from slr_bucket.pipeline import prepare_run_dirs, refresh_latest, setup_logging, write_catalog_outputs, write_run_readme\n",
    "from slr_bucket.validation import validate_daily_long\n",
    "\n",
    "run_dirs = prepare_run_dirs(REPO_ROOT, CONFIG)\n",
    "setup_logging(run_dirs['logs'] / 'pipeline.log')\n",
    "logger = logging.getLogger('summary_pipeline')\n",
    "\n",
    "catalog = build_data_catalog(DATA_DIR)\n",
    "write_catalog_outputs(catalog, run_dirs['data'])\n",
    "logger.info('catalog rows=%s', len(catalog))\n",
    "\n",
    "funding_mapping = discover_funding_series(DATA_DIR)\n",
    "logger.info('funding mapping: %s', funding_mapping)\n",
    "\n",
    "daily_long = validate_daily_long(find_daily_long(DATA_DIR))\n",
    "cache_dir = REPO_ROOT / CONFIG.cache_root\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "cache_path = cache_dir / f'daily_long_{CONFIG.to_hash()}.parquet'\n",
    "daily_long.to_parquet(cache_path, index=False)\n",
    "logger.info('daily_long rows=%s saved=%s', len(daily_long), cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 10:56:00,222 INFO summary_pipeline - dependent series: ['sofr', 'wedge']\n",
      "2026-02-26 10:56:00,230 INFO summary_pipeline - tenors: ['2y']\n"
     ]
    }
   ],
   "source": [
    "pivot = daily_long.pivot_table(index=['date','tenor'], columns='series', values='value', aggfunc='last').reset_index()\n",
    "if CONFIG.tenor_subset:\n",
    "    pivot = pivot[pivot['tenor'].isin(CONFIG.tenor_subset)]\n",
    "\n",
    "series_candidates = [c for c in pivot.columns if c not in {'date', 'tenor'}]\n",
    "if CONFIG.dependent_series:\n",
    "    dep_series = [s for s in CONFIG.dependent_series if s in series_candidates]\n",
    "else:\n",
    "    dep_series = series_candidates[: min(len(series_candidates), 5)]\n",
    "\n",
    "if not dep_series:\n",
    "    raise ValueError('No dependent series selected. Check CONFIG.dependent_series or daily_long series availability.')\n",
    "\n",
    "logger.info('dependent series: %s', dep_series)\n",
    "logger.info('tenors: %s', sorted(pivot['tenor'].dropna().astype(str).unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econometric designs\n",
    "\n",
    "- Windowed jumps: pre/post mean-shift regression with HAC SE and bootstrap robustness.\n",
    "- Event-study bins: total-effect and direct-effect specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (7,2) and (7,2) not aligned: 2 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m     jump_rows.append({\u001b[33m'\u001b[39m\u001b[33mevent_date\u001b[39m\u001b[33m'\u001b[39m: event, \u001b[33m'\u001b[39m\u001b[33mtenor\u001b[39m\u001b[33m'\u001b[39m: tenor, \u001b[33m'\u001b[39m\u001b[33mseries\u001b[39m\u001b[33m'\u001b[39m: y, \u001b[33m'\u001b[39m\u001b[33mwindow\u001b[39m\u001b[33m'\u001b[39m: w, \u001b[33m'\u001b[39m\u001b[33mspec\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mdirect\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mestimate\u001b[39m\u001b[33m'\u001b[39m: est_d, \u001b[33m'\u001b[39m\u001b[33mse\u001b[39m\u001b[33m'\u001b[39m: se_d, \u001b[33m'\u001b[39m\u001b[33mbootstrap_se\u001b[39m\u001b[33m'\u001b[39m: np.nan, \u001b[33m'\u001b[39m\u001b[33mci_low\u001b[39m\u001b[33m'\u001b[39m: est_d-\u001b[32m1.96\u001b[39m*se_d \u001b[38;5;28;01mif\u001b[39;00m np.isfinite(est_d) \u001b[38;5;129;01mand\u001b[39;00m np.isfinite(se_d) \u001b[38;5;28;01melse\u001b[39;00m np.nan, \u001b[33m'\u001b[39m\u001b[33mci_high\u001b[39m\u001b[33m'\u001b[39m: est_d+\u001b[32m1.96\u001b[39m*se_d \u001b[38;5;28;01mif\u001b[39;00m np.isfinite(est_d) \u001b[38;5;129;01mand\u001b[39;00m np.isfinite(se_d) \u001b[38;5;28;01melse\u001b[39;00m np.nan, \u001b[33m'\u001b[39m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m: n_d})\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m spec_name, controls \u001b[38;5;129;01min\u001b[39;00m [(\u001b[33m'\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), (\u001b[33m'\u001b[39m\u001b[33mdirect\u001b[39m\u001b[33m'\u001b[39m, CONFIG.direct_controls)]:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     bins_df = \u001b[43mevent_study_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhac_lags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhac_lags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     bins_df[\u001b[33m'\u001b[39m\u001b[33mevent_date\u001b[39m\u001b[33m'\u001b[39m] = event\n\u001b[32m     32\u001b[39m     bins_df[\u001b[33m'\u001b[39m\u001b[33mtenor\u001b[39m\u001b[33m'\u001b[39m] = tenor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\econometrics\\event_study.py:155\u001b[39m, in \u001b[36mevent_study_regression\u001b[39m\u001b[34m(df, y_col, event_date, bins, controls, hac_lags)\u001b[39m\n\u001b[32m    151\u001b[39m res = sm.OLS(y, X).fit()\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m#########\u001b[39;00m\n\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# res = sm.OLS(joined[y_col], Xf).fit()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m robust = \u001b[43m_nw_cov_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhac_lags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m names = \u001b[38;5;28mlist\u001b[39m(Xf.columns)\n\u001b[32m    157\u001b[39m out = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\econometrics\\event_study.py:42\u001b[39m, in \u001b[36m_nw_cov_params\u001b[39m\u001b[34m(model, lags)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_nw_cov_params\u001b[39m(model, lags: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_robustcov_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHAC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:2534\u001b[39m, in \u001b[36mRegressionResults.get_robustcov_results\u001b[39m\u001b[34m(self, cov_type, use_t, **kwargs)\u001b[39m\n\u001b[32m   2529\u001b[39m     res = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   2530\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2531\u001b[39m     res = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m(\n\u001b[32m   2532\u001b[39m         \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.params,\n\u001b[32m   2533\u001b[39m         normalized_cov_params=\u001b[38;5;28mself\u001b[39m.normalized_cov_params,\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m         scale=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m)\n\u001b[32m   2536\u001b[39m res.cov_type = cov_type\n\u001b[32m   2537\u001b[39m \u001b[38;5;66;03m# use_t might already be defined by the class, and already set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\tools\\decorators.py:95\u001b[39m, in \u001b[36mCachedAttribute.__get__\u001b[39m\u001b[34m(self, obj, type)\u001b[39m\n\u001b[32m     93\u001b[39m _cachedval = _cache.get(name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cachedval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     _cachedval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     _cache[name] = _cachedval\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _cachedval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1717\u001b[39m, in \u001b[36mRegressionResults.scale\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1710\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[33;03mA scale factor for the covariance matrix.\u001b[39;00m\n\u001b[32m   1712\u001b[39m \n\u001b[32m   1713\u001b[39m \u001b[33;03mThe Default value is ssr/(n-p).  Note that the square root of `scale`\u001b[39;00m\n\u001b[32m   1714\u001b[39m \u001b[33;03mis often called the standard error of the regression.\u001b[39;00m\n\u001b[32m   1715\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1716\u001b[39m wresid = \u001b[38;5;28mself\u001b[39m.wresid\n\u001b[32m-> \u001b[39m\u001b[32m1717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwresid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwresid\u001b[49m\u001b[43m)\u001b[49m / \u001b[38;5;28mself\u001b[39m.df_resid\n",
      "\u001b[31mValueError\u001b[39m: shapes (7,2) and (7,2) not aligned: 2 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from slr_bucket.econometrics.event_study import jump_estimator, block_bootstrap_jump, event_study_regression\n",
    "from slr_bucket.plotting.plots import plot_series_with_events, plot_event_paths\n",
    "\n",
    "jump_rows = []\n",
    "bin_rows = []\n",
    "for tenor, tdf in pivot.groupby('tenor'):\n",
    "    tdf = tdf.sort_values('date').copy()\n",
    "    for y in dep_series:\n",
    "        if y not in tdf.columns:\n",
    "            continue\n",
    "        sub = tdf[['date', y] + [c for c in CONFIG.direct_controls if c in tdf.columns]].copy()\n",
    "        sub = sub.dropna(subset=[y])\n",
    "        if sub.empty:\n",
    "            warnings.warn(f'No data for {tenor}-{y}')\n",
    "            continue\n",
    "\n",
    "        plot_series_with_events(sub.rename(columns={y: 'dep'}), 'dep', CONFIG.event_dates, f'{tenor} {y}', run_dirs['figures'] / f'series_{tenor}_{y}.png')\n",
    "\n",
    "        for event in CONFIG.event_dates:\n",
    "            for w in CONFIG.windows:\n",
    "                est, se, n = jump_estimator(sub, y, event, w, controls=None, hac_lags=CONFIG.hac_lags)\n",
    "                bse = block_bootstrap_jump(sub, y, event, w, controls=None, reps=CONFIG.bootstrap_reps, block_size=CONFIG.bootstrap_block_size, seed=CONFIG.random_seed)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'total', 'estimate': est, 'se': se, 'bootstrap_se': bse, 'ci_low': est-1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'ci_high': est+1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'n': n})\n",
    "\n",
    "                est_d, se_d, n_d = jump_estimator(sub, y, event, w, controls=CONFIG.direct_controls, hac_lags=CONFIG.hac_lags)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'direct', 'estimate': est_d, 'se': se_d, 'bootstrap_se': np.nan, 'ci_low': est_d-1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'ci_high': est_d+1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'n': n_d})\n",
    "\n",
    "            for spec_name, controls in [('total', None), ('direct', CONFIG.direct_controls)]:\n",
    "                bins_df = event_study_regression(sub, y, event, CONFIG.event_bins, controls=controls, hac_lags=CONFIG.hac_lags)\n",
    "                bins_df['event_date'] = event\n",
    "                bins_df['tenor'] = tenor\n",
    "                bins_df['series'] = y\n",
    "                bins_df['spec'] = spec_name\n",
    "                bin_rows.append(bins_df)\n",
    "                plot_event_paths(bins_df, f'{tenor} {y} {event} {spec_name}', run_dirs['figures'] / f'event_path_{tenor}_{y}_{event}_{spec_name}.png')\n",
    "\n",
    "jump_table = pd.DataFrame(jump_rows)\n",
    "bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n",
    "\n",
    "jump_table.to_csv(run_dirs['tables'] / 'jump_estimates.csv', index=False)\n",
    "if not bin_table.empty:\n",
    "    bin_table.to_csv(run_dirs['tables'] / 'event_study_bins.csv', index=False)\n",
    "\n",
    "jump_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_33452\\4127238930.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>window</th>\n",
       "      <th>spec</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>bootstrap_se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>10</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date tenor series  window    spec  estimate  se  bootstrap_se  \\\n",
       "0  2020-04-01    2y  wedge       3   total       NaN NaN           NaN   \n",
       "1  2020-04-01    2y  wedge       3  direct       NaN NaN           NaN   \n",
       "2  2020-04-01    2y  wedge       5   total       NaN NaN           NaN   \n",
       "3  2020-04-01    2y  wedge       5  direct       NaN NaN           NaN   \n",
       "4  2020-04-01    2y  wedge      10   total       NaN NaN           NaN   \n",
       "\n",
       "   ci_low  ci_high  n  \n",
       "0     NaN      NaN  4  \n",
       "1     NaN      NaN  4  \n",
       "2     NaN      NaN  5  \n",
       "3     NaN      NaN  5  \n",
       "4     NaN      NaN  7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from slr_bucket.econometrics.event_study import jump_estimator, block_bootstrap_jump, event_study_regression\n",
    "from slr_bucket.plotting.plots import plot_series_with_events, plot_event_paths\n",
    "\n",
    "jump_rows = []\n",
    "bin_rows = []\n",
    "for tenor, tdf in pivot.groupby('tenor'):\n",
    "    tdf = tdf.sort_values('date').copy()\n",
    "    for y in dep_series:\n",
    "        if y not in tdf.columns:\n",
    "            continue\n",
    "        # sub = tdf[['date', y] + [c for c in CONFIG.direct_controls if c in tdf.columns]].copy()\n",
    "        \n",
    "        sub = sub.dropna(subset=[y])\n",
    "        if sub.empty:\n",
    "            warnings.warn(f'No data for {tenor}-{y}')\n",
    "            continue\n",
    "\n",
    "        plot_series_with_events(sub.rename(columns={y: 'dep'}), 'dep', CONFIG.event_dates, f'{tenor} {y}', run_dirs['figures'] / f'series_{tenor}_{y}.png')\n",
    "\n",
    "        for event in CONFIG.event_dates:\n",
    "            for w in CONFIG.windows:\n",
    "                est, se, n = jump_estimator(sub, y, event, w, controls=None, hac_lags=CONFIG.hac_lags)\n",
    "                bse = block_bootstrap_jump(sub, y, event, w, controls=None, reps=CONFIG.bootstrap_reps, block_size=CONFIG.bootstrap_block_size, seed=CONFIG.random_seed)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'total', 'estimate': est, 'se': se, 'bootstrap_se': bse, 'ci_low': est-1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'ci_high': est+1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'n': n})\n",
    "\n",
    "                est_d, se_d, n_d = jump_estimator(sub, y, event, w, controls=CONFIG.direct_controls, hac_lags=CONFIG.hac_lags)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'direct', 'estimate': est_d, 'se': se_d, 'bootstrap_se': np.nan, 'ci_low': est_d-1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'ci_high': est_d+1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'n': n_d})\n",
    "\n",
    "            for spec_name, controls in [('total', None), ('direct', CONFIG.direct_controls)]:\n",
    "                bins_df = event_study_regression(sub, y, event, CONFIG.event_bins, controls=controls, hac_lags=CONFIG.hac_lags)\n",
    "                bins_df['event_date'] = event\n",
    "                bins_df['tenor'] = tenor\n",
    "                bins_df['series'] = y\n",
    "                bins_df['spec'] = spec_name\n",
    "                bin_rows.append(bins_df)\n",
    "                plot_event_paths(bins_df, f'{tenor} {y} {event} {spec_name}', run_dirs['figures'] / f'event_path_{tenor}_{y}_{event}_{spec_name}.png')\n",
    "\n",
    "jump_table = pd.DataFrame(jump_rows)\n",
    "bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n",
    "\n",
    "jump_table.to_csv(run_dirs['tables'] / 'jump_estimates.csv', index=False)\n",
    "if not bin_table.empty:\n",
    "    bin_table.to_csv(run_dirs['tables'] / 'event_study_bins.csv', index=False)\n",
    "\n",
    "jump_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\src\\slr_bucket\\plotting\\plots.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(df[\"term\"], rotation=45, ha=\"right\")\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_33452\\4127238930.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>window</th>\n",
       "      <th>spec</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>bootstrap_se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>5</td>\n",
       "      <td>direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>10</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date tenor series  window    spec  estimate  se  bootstrap_se  \\\n",
       "0  2020-04-01    2y  wedge       3   total       NaN NaN           NaN   \n",
       "1  2020-04-01    2y  wedge       3  direct       NaN NaN           NaN   \n",
       "2  2020-04-01    2y  wedge       5   total       NaN NaN           NaN   \n",
       "3  2020-04-01    2y  wedge       5  direct       NaN NaN           NaN   \n",
       "4  2020-04-01    2y  wedge      10   total       NaN NaN           NaN   \n",
       "\n",
       "   ci_low  ci_high  n  \n",
       "0     NaN      NaN  4  \n",
       "1     NaN      NaN  4  \n",
       "2     NaN      NaN  5  \n",
       "3     NaN      NaN  5  \n",
       "4     NaN      NaN  7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from slr_bucket.econometrics.event_study import jump_estimator, block_bootstrap_jump, event_study_regression\n",
    "from slr_bucket.plotting.plots import plot_series_with_events, plot_event_paths\n",
    "\n",
    "jump_rows = []\n",
    "bin_rows = []\n",
    "for tenor, tdf in pivot.groupby('tenor'):\n",
    "    tdf = tdf.sort_values('date').copy()\n",
    "    for y in dep_series:\n",
    "        if y not in tdf.columns:\n",
    "            continue\n",
    "        # sub = tdf[['date', y] + [c for c in CONFIG.direct_controls if c in tdf.columns]].copy()\n",
    "        \n",
    "        sub = sub.dropna(subset=[y])\n",
    "        if sub.empty:\n",
    "            warnings.warn(f'No data for {tenor}-{y}')\n",
    "            continue\n",
    "\n",
    "        plot_series_with_events(sub.rename(columns={y: 'dep'}), 'dep', CONFIG.event_dates, f'{tenor} {y}', run_dirs['figures'] / f'series_{tenor}_{y}.png')\n",
    "\n",
    "        for event in CONFIG.event_dates:\n",
    "            for w in CONFIG.windows:\n",
    "                est, se, n = jump_estimator(sub, y, event, w, controls=None, hac_lags=CONFIG.hac_lags)\n",
    "                bse = block_bootstrap_jump(sub, y, event, w, controls=None, reps=CONFIG.bootstrap_reps, block_size=CONFIG.bootstrap_block_size, seed=CONFIG.random_seed)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'total', 'estimate': est, 'se': se, 'bootstrap_se': bse, 'ci_low': est-1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'ci_high': est+1.96*se if np.isfinite(est) and np.isfinite(se) else np.nan, 'n': n})\n",
    "\n",
    "                est_d, se_d, n_d = jump_estimator(sub, y, event, w, controls=CONFIG.direct_controls, hac_lags=CONFIG.hac_lags)\n",
    "                jump_rows.append({'event_date': event, 'tenor': tenor, 'series': y, 'window': w, 'spec': 'direct', 'estimate': est_d, 'se': se_d, 'bootstrap_se': np.nan, 'ci_low': est_d-1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'ci_high': est_d+1.96*se_d if np.isfinite(est_d) and np.isfinite(se_d) else np.nan, 'n': n_d})\n",
    "\n",
    "            for spec_name, controls in [('total', None), ('direct', CONFIG.direct_controls)]:\n",
    "                bins_df = event_study_regression(sub, y, event, CONFIG.event_bins, controls=controls, hac_lags=CONFIG.hac_lags)\n",
    "                bins_df['event_date'] = event\n",
    "                bins_df['tenor'] = tenor\n",
    "                bins_df['series'] = y\n",
    "                bins_df['spec'] = spec_name\n",
    "                bin_rows.append(bins_df)\n",
    "                plot_event_paths(bins_df, f'{tenor} {y} {event} {spec_name}', run_dirs['figures'] / f'event_path_{tenor}_{y}_{event}_{spec_name}.png')\n",
    "\n",
    "jump_table = pd.DataFrame(jump_rows)\n",
    "bin_table = pd.concat(bin_rows, ignore_index=True) if bin_rows else pd.DataFrame()\n",
    "\n",
    "jump_table.to_csv(run_dirs['tables'] / 'jump_estimates.csv', index=False)\n",
    "if not bin_table.empty:\n",
    "    bin_table.to_csv(run_dirs['tables'] / 'event_study_bins.csv', index=False)\n",
    "\n",
    "jump_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility + how to rerun\n",
    "\n",
    "- Run all cells in Jupyter, or execute `python scripts/run_notebook.py`.\n",
    "- Outputs are timestamped + config-hashed, and `latest/` is refreshed each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\summary_pipeline\\20260226_165001_f562fdf488e4\n",
      "Latest: C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\summary_pipeline\\latest\n",
      "Latest refreshed: C:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\outputs\\summary_pipeline\\latest\n"
     ]
    }
   ],
   "source": [
    "notes = (\n",
    "    f\"Processed {len(daily_long)} daily_long rows across {daily_long['tenor'].nunique()} tenors and \"\n",
    "    f\"{daily_long['series'].nunique()} series.\"\n",
    ")\n",
    "write_run_readme(run_dirs['run'], CONFIG, notes)\n",
    "print('Run dir:', run_dirs['run'])\n",
    "print('Latest:', REPO_ROOT / CONFIG.output_root / 'latest')\n",
    "latest_dir = refresh_latest(REPO_ROOT, CONFIG, run_dirs['run'])\n",
    "print('Latest refreshed:', latest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "\n",
    "Basic diagnostics for missingness and sample support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenor</th>\n",
       "      <th>series</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2y</td>\n",
       "      <td>sofr</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2y</td>\n",
       "      <td>wedge</td>\n",
       "      <td>7</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.039158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tenor series  count  mean       std\n",
       "0    2y   sofr      7  0.01  0.000000\n",
       "1    2y  wedge      7  0.14  0.039158"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity = (\n",
    "    daily_long.groupby(['tenor','series'])['value']\n",
    "    .agg(['count','mean','std'])\n",
    "    .reset_index()\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "sanity.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
