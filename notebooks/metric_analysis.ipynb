{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis pipeline (cross-strategy arbitrage spreads)\n",
    "\n",
    "This notebook implements a cross-strategy event-study + mechanism pipeline for:\n",
    "\n",
    "- **TIPS–Treasury** (arb_2/5/10)\n",
    "- **UST spot–futures** basis (2/5/10)\n",
    "- **CIP** (3m; multiple currencies)\n",
    "- **Equity spot–futures** basis (SPX/NDX/INDU)\n",
    "\n",
    "Key convention: all series are transformed to a **mispricing magnitude** measure in **bps** (`y_abs_bps`), so **negative coefficients imply compression toward 0**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\notebooks\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "sys.path.insert(2, \"../src\")\n",
    "if 'src' in os.getcwd():\n",
    "    os.chdir(os.path.pardir)\n",
    "    print(os.getcwd())\n",
    "else:\n",
    "    print(os.getcwd())\n",
    "from slr_bucket.econometrics.event_study import add_event_time, event_study_regression, jump_estimator\n",
    "from slr_bucket.io import build_data_catalog, load_any_table, resolve_dataset_path, as_daily_date, coerce_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\2288107824.py:70: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  run_stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/Owner/Box/Winter26/slr_bucket/outputs/summary_pipeline/20260228_203643_01492bfdea93')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    # Sample window for all analysis outputs\n",
    "    \"sample_start\": \"2019-01-01\",\n",
    "    \"sample_end\": \"2021-12-31\",\n",
    "\n",
    "    # Core SLR dates\n",
    "    \"events\": [\"2020-04-01\", \"2021-03-19\", \"2021-03-31\"],\n",
    "\n",
    "    # Trading-day windows / bins (in trading-day units, not calendar days)\n",
    "    \"windows\": [20, 60],\n",
    "    \"event_bins\": [(-60, -41), (-40, -21), (-20, -1), (0, 0), (1, 20), (21, 40), (41, 60)],\n",
    "    \"event_range\": (-60, 60),\n",
    "\n",
    "    # Treasury tenors to keep for Treasury-based strategies\n",
    "    \"tenors_required\": [2, 5, 10],\n",
    "\n",
    "    # Outcomes (dataset ids resolved under data/series/)\n",
    "    \"outcomes\": {\n",
    "        \"tips_treas\": {\"dataset\": \"tips_treasury_implied_rf_2010\", \"pattern\": \"arb_\", \"treasury_based\": True},\n",
    "        \"ust_spot_fut\": {\"dataset\": \"treasury_sf_output\", \"pattern\": \"Treasury_SF_\", \"treasury_based\": True},\n",
    "        \"cip\": {\"dataset\": \"cip_spreads_3m_bps\", \"pattern\": \"CIP_\", \"treasury_based\": False},\n",
    "        \"eq_spot_fut\": {\n",
    "            # \"datasets\": [\"equity_spot_spread_SPX\", \"equity_spot_spread_NDX\", \"equity_spot_spread_INDU\"],\n",
    "            \"datasets\": [\"equity_spot_spread_INDU\", \"equity_spot_spread_NDX\", \"equity_spot_spread_SPX\"],\n",
    "            \"pattern\": \"spread_\",\n",
    "            \"treasury_based\": False,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # Sign convention: multiply raw series by SIGN_MAP[strategy] to orient them\n",
    "    # (then we use y_abs_bps = abs( oriented series ) as the main dependent variable)\n",
    "    \"sign_map\": {\n",
    "        \"tips_treas\": +1,\n",
    "        \"ust_spot_fut\": -1,   # file is mostly negative; flip so deviations are mostly positive\n",
    "        \"cip\": +1,\n",
    "        \"eq_spot_fut\": +1,\n",
    "    },\n",
    "\n",
    "    # Controls (daily)\n",
    "    \"total_controls\": [\"VIX\", \"HY_OAS\", \"BAA10Y\", \"issu_7_bil\", \"issu_14_bil\", \"issu_30_bil\"],\n",
    "    \"direct_controls\": [\"VIX\", \"HY_OAS\", \"BAA10Y\", \"issu_7_bil\", \"issu_14_bil\", \"issu_30_bil\", \"SOFR\", \"spr_tgcr\", \"spr_effr\"],\n",
    "\n",
    "    # \"Near-zero\" thresholds in bps\n",
    "    \"near_zero_deltas\": [5.0, 10.0],\n",
    "\n",
    "    # Inference\n",
    "    \"hac_lags_daily\": 5,\n",
    "    \"hac_lags_weekly\": 2,\n",
    "\n",
    "    # choose one: \"TIPS\", \"CIP\", \"EQUITY_INDU\", \"EQUITY_NDX\", \"EQUITY_SPY\"\n",
    "    \"mode\": \"TIPS\",\n",
    "\n",
    "    # CIP file + columns\n",
    "    \"cip_path\": \"data/series/cip_spreads_3m_bps.csv\",\n",
    "    \"cip_cols\": [\"CIP_AUD_ln\",\"CIP_CAD_ln\",\"CIP_CHF_ln\",\"CIP_EUR_ln\",\"CIP_GBP_ln\",\"CIP_JPY_ln\",\"CIP_NZD_ln\",\"CIP_SEK_ln\"],\n",
    "\n",
    "    # Equity files + single column in each\n",
    "    \"equity_indu_path\": \"data/series/equity_spot_spread_INDU.csv\",\n",
    "    \"equity_indu_col\": \"spread_INDU_filtered\",\n",
    "\n",
    "    \"equity_ndx_path\": \"data/series/equity_spot_spread_NDX.csv\",\n",
    "    \"equity_ndx_col\": \"spread_NDX_filtered\",\n",
    "\n",
    "    \"equity_spy_path\": \"data/series/equity_spot_spread_SPY.csv\",\n",
    "    \"equity_spy_col\": \"spread_SPY_filtered\",\n",
    "}\n",
    "\n",
    "repo_root = Path.cwd().parent\n",
    "cfg_hash = hashlib.sha256(json.dumps(CONFIG, sort_keys=True).encode()).hexdigest()[:12]\n",
    "run_stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = repo_root / \"outputs\" / \"summary_pipeline\" / f\"{run_stamp}_{cfg_hash}\"\n",
    "for sub in [\"figures\", \"tables\", \"data\", \"logs\"]:\n",
    "    (run_dir / sub).mkdir(parents=True, exist_ok=True)\n",
    "latest_dir = repo_root / \"outputs\" / \"summary_pipeline\" / \"latest\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(run_dir / \"logs\" / \"pipeline.log\"), logging.StreamHandler()],\n",
    "    force=True,\n",
    ")\n",
    "logger = logging.getLogger(\"summary_pipeline_multi\")\n",
    "run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: unit normalization, trading-day event time, binned event-study, Stargazer patch\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def _to_bps(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Heuristic conversion to bps. Handles:\n",
    "    - bps already (typical magnitudes: 1-500)\n",
    "    - percent (e.g., 3.15 for 3.15%) -> *100\n",
    "    - decimal (e.g., 0.0315 for 3.15%) -> *10000\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(x, errors=\"coerce\")\n",
    "    med = float(np.nanmedian(np.abs(s.values))) if np.isfinite(np.nanmedian(np.abs(s.values))) else np.nan\n",
    "    if not np.isfinite(med) or med == 0:\n",
    "        return s\n",
    "\n",
    "    # likely decimal (0.0005 = 5 bps) or (0.03 = 300 bps)\n",
    "    if med < 0.05:\n",
    "        return s * 10000.0\n",
    "\n",
    "    # likely percent units (3.5 = 350 bps)\n",
    "    if med < 20.0:\n",
    "        return s * 100.0\n",
    "\n",
    "    # already bps\n",
    "    return s\n",
    "\n",
    "def add_event_time_trading(df: pd.DataFrame, event_date: str, group_col: str = \"series_id\") -> pd.DataFrame:\n",
    "    \"\"\"Add event_time in *trading-day* index units within each series.\n",
    "    event_time=0 is the nearest available trading date >= event_date, else last date if event_date beyond sample.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"date\"])\n",
    "    t0 = pd.Timestamp(event_date)\n",
    "\n",
    "    def _apply(g):\n",
    "        g = g.sort_values(\"date\").copy()\n",
    "        dates = g[\"date\"].values\n",
    "        # choose first date >= t0; if none, choose last\n",
    "        idx0 = np.searchsorted(dates, np.datetime64(t0), side=\"left\")\n",
    "        if idx0 >= len(dates):\n",
    "            idx0 = len(dates) - 1\n",
    "        g[\"event_t0_used\"] = pd.Timestamp(dates[idx0])\n",
    "        g[\"event_time\"] = np.arange(len(g), dtype=int) - int(idx0)\n",
    "        return g\n",
    "\n",
    "    return out.groupby(group_col, group_keys=False).apply(_apply)\n",
    "\n",
    "def bin_event_time(et: pd.Series, bins: list[tuple[int,int]]) -> pd.Categorical:\n",
    "    labels = [f\"bin_[{a},{b}]\" for a,b in bins]\n",
    "    # bins are closed intervals; assign by masking\n",
    "    cat = pd.Series(pd.NA, index=et.index, dtype=\"object\")\n",
    "    for (a,b),lab in zip(bins, labels):\n",
    "        cat[(et>=a) & (et<=b)] = lab\n",
    "    return pd.Categorical(cat, categories=labels, ordered=True)\n",
    "\n",
    "def patch_stargazer_globals():\n",
    "    \"\"\"Inject pd/np into any loaded stargazer modules that forgot to import them.\"\"\"\n",
    "    import pandas as _pd\n",
    "    import numpy as _np\n",
    "    for name, mod in list(sys.modules.items()):\n",
    "        if name and name.startswith(\"stargazer\") and mod is not None:\n",
    "            if not hasattr(mod, \"pd\"):\n",
    "                setattr(mod, \"pd\", _pd)\n",
    "            if not hasattr(mod, \"np\"):\n",
    "                setattr(mod, \"np\", _np)\n",
    "\n",
    "def sanitize_for_patsy(df: pd.DataFrame, category_cols: list[str] | None = None) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        dt = str(out[c].dtype)\n",
    "        if dt in (\"Int64\", \"Int32\", \"Int16\", \"boolean\"):\n",
    "            out[c] = out[c].astype(\"float64\")\n",
    "    if category_cols:\n",
    "        for c in category_cols:\n",
    "            if c in out.columns:\n",
    "                out[c] = out[c].astype(\"category\")\n",
    "    return out\n",
    "\n",
    "def run_pooled_jump(sub: pd.DataFrame, y_col: str, controls: list[str], fe_col: str, interact_treasury: bool = True):\n",
    "    use_controls = [c for c in controls if c in sub.columns]\n",
    "    x_terms = [\"post\"] + use_controls + [f\"C({fe_col})\"]\n",
    "    if interact_treasury and \"treasury_based\" in sub.columns:\n",
    "        x_terms.insert(1, \"post:treasury_based\")\n",
    "    rhs = \" + \".join(x_terms)\n",
    "    reg = sub[[y_col, \"post\", fe_col, \"treasury_based\", *use_controls]].dropna().copy()\n",
    "    reg = sanitize_for_patsy(reg, category_cols=[fe_col])\n",
    "    res = ols(f\"{y_col} ~ {rhs}\", data=reg).fit()\n",
    "    robust = res.get_robustcov_results(cov_type=\"HAC\", maxlags=CONFIG[\"hac_lags_daily\"])\n",
    "    return robust, reg\n",
    "\n",
    "def run_relief_reg(df: pd.DataFrame, y_col: str, controls: list[str], fe_col: str, interact_treasury: bool = True):\n",
    "    use_controls = [c for c in controls if c in df.columns]\n",
    "    x_terms = [\"relief\"] + use_controls + [f\"C({fe_col})\"]\n",
    "    if interact_treasury and \"treasury_based\" in df.columns:\n",
    "        x_terms.insert(1, \"relief:treasury_based\")\n",
    "    rhs = \" + \".join(x_terms)\n",
    "    reg = df[[y_col, \"relief\", fe_col, \"treasury_based\", *use_controls]].dropna().copy()\n",
    "    reg = sanitize_for_patsy(reg, category_cols=[fe_col])\n",
    "    res = ols(f\"{y_col} ~ {rhs}\", data=reg).fit()\n",
    "    robust = res.get_robustcov_results(cov_type=\"HAC\", maxlags=CONFIG[\"hac_lags_daily\"])\n",
    "    return robust, reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd978007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data map (required)\n",
    "\n",
    "Outcomes (data/series):\n",
    "- tips_treasury_implied_rf_2010.parquet  (arb_*)\n",
    "- treasury_sf_output.csv                (Treasury_SF_* tenors)\n",
    "- cip_spreads_3m_bps.csv                (CIP_* currencies)\n",
    "- equity_spot_spread_{SPX,NDX,INDU}.csv  (spread_*)\n",
    "\n",
    "Controls:\n",
    "- preferred: data/intermediate/analysis_panel (must contain CONFIG['direct_controls'])\n",
    "- fallback: FRED credit/risk + repo rates + Treasury issuance\n",
    "\n",
    "Mechanism proxies (optional):\n",
    "- primary_dealer_stats_ofr_stfm_nypd_long\n",
    "- bank_exposure_y9c_agg_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>layer</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "      <th>frequency</th>\n",
       "      <th>date_min</th>\n",
       "      <th>date_max</th>\n",
       "      <th>key_columns</th>\n",
       "      <th>join_hints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>5476</td>\n",
       "      <td>date,spread_2y_bps,spread_5y_bps,spread_10y_bp...</td>\n",
       "      <td>daily</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>420</td>\n",
       "      <td>date,bid_ask_spread,pubout,n_issues</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1980-01-31</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>keys:date | layer:intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>1209</td>\n",
       "      <td>date,fed_assets</td>\n",
       "      <td>weekly</td>\n",
       "      <td>2002-12-18</td>\n",
       "      <td>2026-02-11</td>\n",
       "      <td>date</td>\n",
       "      <td>weekly:date | keys:date | layer:intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>1209</td>\n",
       "      <td>date,fed_treasury_holdings</td>\n",
       "      <td>weekly</td>\n",
       "      <td>2002-12-18</td>\n",
       "      <td>2026-02-11</td>\n",
       "      <td>date</td>\n",
       "      <td>weekly:date | keys:date | layer:intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>751</td>\n",
       "      <td>date,sofr,sofr_volume</td>\n",
       "      <td>daily</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>3752</td>\n",
       "      <td>date,spread_2y_bps,spread_5y_bps,spread_10y_bp...</td>\n",
       "      <td>daily</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>3955</td>\n",
       "      <td>Date,AUD,CAD,CHF,EUR,GBP,JPY,NZD,SEK,USD</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td>layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>3913</td>\n",
       "      <td>('SPX Index', 'PX_LAST'),('SPX Index', 'IDX_ES...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td>layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>14</td>\n",
       "      <td>report_date,total_assets,total_reserves,total_...</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>report_date</td>\n",
       "      <td>quarterly:report_date | keys:report_date | lay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>14</td>\n",
       "      <td>report_date,total_assets,total_reserves,total_...</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>report_date</td>\n",
       "      <td>quarterly:report_date | keys:report_date | lay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>126</td>\n",
       "      <td>bank_id,report_date,assets,reserves,ust,reserv...</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>report_date</td>\n",
       "      <td>quarterly:report_date | keys:report_date | lay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>126</td>\n",
       "      <td>bank_id,report_date,assets,reserves,ust,reserv...</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>report_date</td>\n",
       "      <td>quarterly:report_date | keys:report_date | lay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>1097</td>\n",
       "      <td>date,total_assets,total_reserves,total_ust,n_b...</td>\n",
       "      <td>daily</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>8</td>\n",
       "      <td>report_date,total_assets,total_reserves,total_...</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>report_date</td>\n",
       "      <td>quarterly:report_date | keys:report_date | lay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>2792</td>\n",
       "      <td>bank_id,report_date,assets,reserves,ust,reserv...</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>report_date</td>\n",
       "      <td>quarterly:report_date | keys:report_date | lay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>794</td>\n",
       "      <td>date,VIX,HY_OAS,BAA10Y</td>\n",
       "      <td>daily</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>794</td>\n",
       "      <td>date,VIX,HY_OAS,BAA10Y</td>\n",
       "      <td>daily</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>22824</td>\n",
       "      <td>date,mnemonic,series_name,value</td>\n",
       "      <td>weekly</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>date,value</td>\n",
       "      <td>weekly:date | keys:date | layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>22824</td>\n",
       "      <td>date,mnemonic,series_name,value</td>\n",
       "      <td>weekly</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>date,value</td>\n",
       "      <td>weekly:date | keys:date | layer:raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...</td>\n",
       "      <td>raw</td>\n",
       "      <td>784</td>\n",
       "      <td>date,SOFR,TGCR,BGCR,sofr_minus_tgcr,sofr_minus...</td>\n",
       "      <td>daily</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>date</td>\n",
       "      <td>daily:date | keys:date | layer:raw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path         layer   rows  \\\n",
       "0   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...  intermediate   5476   \n",
       "1   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...  intermediate    420   \n",
       "2   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...  intermediate   1209   \n",
       "3   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...  intermediate   1209   \n",
       "4   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...  intermediate    751   \n",
       "5   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\in...  intermediate   3752   \n",
       "6   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw   3955   \n",
       "7   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw   3913   \n",
       "8   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw     14   \n",
       "9   c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw     14   \n",
       "10  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw    126   \n",
       "11  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw    126   \n",
       "12  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw   1097   \n",
       "13  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw      8   \n",
       "14  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw   2792   \n",
       "15  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw    794   \n",
       "16  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw    794   \n",
       "17  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw  22824   \n",
       "18  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw  22824   \n",
       "19  c:\\Users\\Owner\\Box\\Winter26\\slr_bucket\\data\\ra...           raw    784   \n",
       "\n",
       "                                              columns  frequency   date_min  \\\n",
       "0   date,spread_2y_bps,spread_5y_bps,spread_10y_bp...      daily 2010-01-04   \n",
       "1                 date,bid_ask_spread,pubout,n_issues    monthly 1980-01-31   \n",
       "2                                     date,fed_assets     weekly 2002-12-18   \n",
       "3                          date,fed_treasury_holdings     weekly 2002-12-18   \n",
       "4                               date,sofr,sofr_volume      daily 2019-01-02   \n",
       "5   date,spread_2y_bps,spread_5y_bps,spread_10y_bp...      daily 2010-01-04   \n",
       "6            Date,AUD,CAD,CHF,EUR,GBP,JPY,NZD,SEK,USD    unknown        NaT   \n",
       "7   ('SPX Index', 'PX_LAST'),('SPX Index', 'IDX_ES...    unknown        NaT   \n",
       "8   report_date,total_assets,total_reserves,total_...  quarterly        NaT   \n",
       "9   report_date,total_assets,total_reserves,total_...  quarterly        NaT   \n",
       "10  bank_id,report_date,assets,reserves,ust,reserv...  quarterly        NaT   \n",
       "11  bank_id,report_date,assets,reserves,ust,reserv...  quarterly        NaT   \n",
       "12  date,total_assets,total_reserves,total_ust,n_b...      daily 2019-01-01   \n",
       "13  report_date,total_assets,total_reserves,total_...  quarterly        NaT   \n",
       "14  bank_id,report_date,assets,reserves,ust,reserv...  quarterly        NaT   \n",
       "15                             date,VIX,HY_OAS,BAA10Y      daily 2019-01-02   \n",
       "16                             date,VIX,HY_OAS,BAA10Y      daily 2019-01-02   \n",
       "17                    date,mnemonic,series_name,value     weekly 2019-01-02   \n",
       "18                    date,mnemonic,series_name,value     weekly 2019-01-02   \n",
       "19  date,SOFR,TGCR,BGCR,sofr_minus_tgcr,sofr_minus...      daily 2019-01-01   \n",
       "\n",
       "     date_max  key_columns                                         join_hints  \n",
       "0  2024-12-31         date        daily:date | keys:date | layer:intermediate  \n",
       "1  2014-12-31         date                     keys:date | layer:intermediate  \n",
       "2  2026-02-11         date       weekly:date | keys:date | layer:intermediate  \n",
       "3  2026-02-11         date       weekly:date | keys:date | layer:intermediate  \n",
       "4  2021-12-31         date        daily:date | keys:date | layer:intermediate  \n",
       "5  2024-12-31         date        daily:date | keys:date | layer:intermediate  \n",
       "6         NaT                                                       layer:raw  \n",
       "7         NaT                                                       layer:raw  \n",
       "8         NaT  report_date  quarterly:report_date | keys:report_date | lay...  \n",
       "9         NaT  report_date  quarterly:report_date | keys:report_date | lay...  \n",
       "10        NaT  report_date  quarterly:report_date | keys:report_date | lay...  \n",
       "11        NaT  report_date  quarterly:report_date | keys:report_date | lay...  \n",
       "12 2022-01-01         date                 daily:date | keys:date | layer:raw  \n",
       "13        NaT  report_date  quarterly:report_date | keys:report_date | lay...  \n",
       "14        NaT  report_date  quarterly:report_date | keys:report_date | lay...  \n",
       "15 2021-12-31         date                 daily:date | keys:date | layer:raw  \n",
       "16 2021-12-31         date                 daily:date | keys:date | layer:raw  \n",
       "17 2021-12-29   date,value                weekly:date | keys:date | layer:raw  \n",
       "18 2021-12-29   date,value                weekly:date | keys:date | layer:raw  \n",
       "19 2021-12-31         date                 daily:date | keys:date | layer:raw  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = build_data_catalog(repo_root / \"data\")\n",
    "catalog.to_csv(run_dir / \"data\" / \"data_catalog.csv\", index=False)\n",
    "catalog.to_parquet(run_dir / \"data\" / \"data_catalog.parquet\", index=False)\n",
    "catalog.to_markdown(run_dir / \"data\" / \"data_catalog.md\", index=False)\n",
    "catalog.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ust_spot_fut</th>\n",
       "      <td>1146.455556</td>\n",
       "      <td>3370.055556</td>\n",
       "      <td>4853.906667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0.50         0.90         0.99\n",
       "strategy                                           \n",
       "ust_spot_fut  1146.455556  3370.055556  4853.906667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and stack outcomes across strategies into a single long panel (bps units)\n",
    "\n",
    "def load_tips_treas():\n",
    "    path = resolve_dataset_path(CONFIG[\"outcomes\"][\"tips_treas\"][\"dataset\"], expected_dir=repo_root / \"data\" / \"series\")\n",
    "    df = load_any_table(path)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df[\"date\"] = as_daily_date(df[\"date\"])\n",
    "    cols = sorted([c for c in df.columns if c.startswith(CONFIG[\"outcomes\"][\"tips_treas\"][\"pattern\"])],\n",
    "                  key=lambda c: int(c.split(\"_\")[1]))\n",
    "    if not cols:\n",
    "        raise ValueError(\"tips_treas: no arb_* columns found\")\n",
    "    long = df[[\"date\", *cols]].melt(\"date\", var_name=\"raw_name\", value_name=\"y_raw\")\n",
    "    long[\"tenor\"] = long[\"raw_name\"].str.extract(r\"arb_(\\d+)\").astype(float).astype(\"Int64\")\n",
    "    long[\"strategy\"] = \"tips_treas\"\n",
    "    long[\"series_id\"] = long[\"strategy\"] + \"_\" + long[\"tenor\"].astype(\"Int64\").astype(str) + \"y\"\n",
    "    long[\"treasury_based\"] = 1\n",
    "    long[\"y_raw_bps\"] = pd.to_numeric(long[\"y_raw\"], errors=\"coerce\")\n",
    "    return long[[\"date\",\"strategy\",\"series_id\",\"tenor\",\"treasury_based\",\"y_raw_bps\"]]\n",
    "\n",
    "def load_ust_spot_fut():\n",
    "    path = resolve_dataset_path(CONFIG[\"outcomes\"][\"ust_spot_fut\"][\"dataset\"], expected_dir=repo_root / \"data\" / \"series\")\n",
    "    df = load_any_table(path)\n",
    "    # handle Date column name\n",
    "    date_col = \"Date\" if \"Date\" in df.columns else \"date\"\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df[\"date\"] = as_daily_date(df[date_col])\n",
    "    cols = [c for c in df.columns if c.startswith(CONFIG[\"outcomes\"][\"ust_spot_fut\"][\"pattern\"])]\n",
    "    if not cols:\n",
    "        raise ValueError(\"ust_spot_fut: no Treasury_SF_* columns found\")\n",
    "    long = df[[\"date\", *cols]].melt(\"date\", var_name=\"raw_name\", value_name=\"y_raw\")\n",
    "    long[\"tenor\"] = long[\"raw_name\"].str.extract(r\"(\\d+)Y\").astype(float).astype(\"Int64\")\n",
    "    long[\"strategy\"] = \"ust_spot_fut\"\n",
    "    long[\"series_id\"] = long[\"strategy\"] + \"_\" + long[\"tenor\"].astype(\"Int64\").astype(str) + \"y\"\n",
    "    long[\"treasury_based\"] = 1\n",
    "    long[\"y_raw_bps\"] = _to_bps(long[\"y_raw\"])\n",
    "    return long[[\"date\",\"strategy\",\"series_id\",\"tenor\",\"treasury_based\",\"y_raw_bps\"]]\n",
    "\n",
    "def load_cip():\n",
    "    path = resolve_dataset_path(CONFIG[\"outcomes\"][\"cip\"][\"dataset\"], expected_dir=repo_root / \"data\" / \"series\")\n",
    "    df = load_any_table(path)\n",
    "    date_col = \"Date\" if \"Date\" in df.columns else \"date\"\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df[\"date\"] = as_daily_date(df[date_col])\n",
    "    # cols = [c for c in df.columns if c.startswith(CONFIG[\"outcomes\"][\"cip\"][\"pattern\"]) and c != date_col]\n",
    "    cols = [\n",
    "        \"CIP_AUD_ln\",\"CIP_CAD_ln\",\"CIP_CHF_ln\",\"CIP_EUR_ln\",\n",
    "        \"CIP_GBP_ln\",\"CIP_JPY_ln\",\"CIP_NZD_ln\",\"CIP_SEK_ln\",\n",
    "    ]\n",
    "    missing = sorted(set(cols) - set(df.columns))\n",
    "    if missing:\n",
    "        raise ValueError(f\"cip_spreads_3m_bps is missing columns: {missing}\")\n",
    "\n",
    "    if not cols:\n",
    "        raise ValueError(\"cip: no CIP_* columns found\")\n",
    "    long = df[[\"date\", *cols]].melt(\"date\", var_name=\"raw_name\", value_name=\"y_raw\")\n",
    "    # currency identifier\n",
    "    long[\"ccy\"] = long[\"raw_name\"].str.replace(\"CIP_\",\"\", regex=False).str.replace(\"_ln\",\"\", regex=False)\n",
    "    long[\"tenor\"] = \"3m\"\n",
    "    long[\"strategy\"] = \"cip\"\n",
    "    long[\"series_id\"] = long[\"strategy\"] + \"_\" + long[\"ccy\"] + \"_3m\"\n",
    "    long[\"treasury_based\"] = 0\n",
    "    # long[\"y_raw_bps\"] = _to_bps(long[\"y_raw\"])\n",
    "    long[\"y_raw_bps\"] = pd.to_numeric(long[\"y_raw\"], errors=\"coerce\")\n",
    "    return long[[\"date\",\"strategy\",\"series_id\",\"tenor\",\"treasury_based\",\"y_raw_bps\"]]\n",
    "\n",
    "def load_equity():\n",
    "    out = []\n",
    "    for ds in CONFIG[\"outcomes\"][\"eq_spot_fut\"][\"datasets\"]:\n",
    "        path = resolve_dataset_path(ds, expected_dir=repo_root / \"data\" / \"series\")\n",
    "        df = load_any_table(path)\n",
    "        date_col = \"Date\" if \"Date\" in df.columns else \"date\"\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df[\"date\"] = as_daily_date(df[date_col])\n",
    "\n",
    "        # # pick a spread column (prefer raw spread_*, avoid *_filtered if raw exists)\n",
    "        # spread_cols = [c for c in df.columns if c.startswith(CONFIG[\"outcomes\"][\"eq_spot_fut\"][\"pattern\"])]\n",
    "        # if not spread_cols:\n",
    "        #     raise ValueError(f\"{ds}: no spread_* columns found\")\n",
    "\n",
    "        # # heuristic: prefer non-filtered 'spread_<INDEX>' if present\n",
    "        # preferred = None\n",
    "        # for c in spread_cols:\n",
    "        #     if \"filtered\" not in c.lower():\n",
    "        #         preferred = c\n",
    "        #         break\n",
    "        # if preferred is None:\n",
    "        #     preferred = spread_cols[0]\n",
    "        idx_name = ds.replace(\"equity_spot_spread_\",\"\")  # INDU, NDX, SPY\n",
    "        preferred = f\"spread_{idx_name}_filtered\"\n",
    "        if preferred not in df.columns:\n",
    "            raise ValueError(f\"{ds}: expected column '{preferred}' not found. Available: {list(df.columns)}\")\n",
    "\n",
    "        idx_name = ds.replace(\"equity_spot_spread_\",\"\")\n",
    "        tmp = df[[\"date\", preferred]].copy()\n",
    "        tmp[\"strategy\"] = \"eq_spot_fut\"\n",
    "        tmp[\"tenor\"] = \"index\"\n",
    "        tmp[\"series_id\"] = \"eq_\" + idx_name\n",
    "        tmp[\"treasury_based\"] = 0\n",
    "        tmp[\"y_raw_bps\"] = _to_bps(tmp[preferred])\n",
    "        out.append(tmp[[\"date\",\"strategy\",\"series_id\",\"tenor\",\"treasury_based\",\"y_raw_bps\"]])\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "# Build stacked panel\n",
    "# spreads_long = pd.concat(\n",
    "#     [load_tips_treas(), load_ust_spot_fut(), load_cip(), load_equity()],\n",
    "#     ignore_index=True\n",
    "# )\n",
    "# CIP ONLY \n",
    "# spreads_long = load_cip().copy()\n",
    "ACTIVE = \"ust_spot_fut\"  # options: \"cip\", \"eq_INDU\", \"eq_NDX\", \"eq_SPX\", \"tips_treas\", \"ust_spot_fut\"\n",
    "\n",
    "if ACTIVE == \"cip\":\n",
    "    spreads_long = load_cip().copy()\n",
    "\n",
    "elif ACTIVE == \"eq_INDU\":\n",
    "    spreads_long = load_equity().copy()\n",
    "    spreads_long = spreads_long[spreads_long[\"series_id\"].astype(str).eq(\"eq_INDU\")]\n",
    "\n",
    "elif ACTIVE == \"eq_NDX\":\n",
    "    spreads_long = load_equity().copy()\n",
    "    spreads_long = spreads_long[spreads_long[\"series_id\"].astype(str).eq(\"eq_NDX\")]\n",
    "\n",
    "elif ACTIVE == \"eq_SPX\":\n",
    "    spreads_long = load_equity().copy()\n",
    "    spreads_long = spreads_long[spreads_long[\"series_id\"].astype(str).eq(\"eq_SPX\")]\n",
    "\n",
    "elif ACTIVE == \"tips_treas\":\n",
    "    spreads_long = load_tips_treas().copy()\n",
    "\n",
    "elif ACTIVE == \"ust_spot_fut\":\n",
    "    spreads_long = load_ust_spot_fut().copy()\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown ACTIVE={ACTIVE}\")\n",
    "\n",
    "# Hard guard: forbid stacked-strategy runs\n",
    "assert spreads_long[\"strategy\"].nunique() == 1\n",
    "\n",
    "# Enforce Treasury tenors\n",
    "keep_tenors = set(CONFIG[\"tenors_required\"])\n",
    "is_treas = spreads_long[\"strategy\"].isin([\"tips_treas\",\"ust_spot_fut\"])\n",
    "spreads_long = spreads_long[~is_treas | spreads_long[\"tenor\"].isin(keep_tenors)].copy()\n",
    "\n",
    "# Normalize dates and drop missing\n",
    "spreads_long[\"date\"] = pd.to_datetime(spreads_long[\"date\"], errors=\"coerce\")\n",
    "spreads_long[\"date\"] = as_daily_date(spreads_long[\"date\"])\n",
    "spreads_long[\"y_raw_bps\"] = pd.to_numeric(spreads_long[\"y_raw_bps\"], errors=\"coerce\")\n",
    "spreads_long = spreads_long.dropna(subset=[\"date\",\"strategy\",\"series_id\",\"y_raw_bps\"]).reset_index(drop=True)\n",
    "\n",
    "# Apply sign map + compute magnitude outcome\n",
    "SIGN_MAP = CONFIG[\"sign_map\"]\n",
    "spreads_long[\"y_bps\"] = spreads_long[\"y_raw_bps\"] * spreads_long[\"strategy\"].map(SIGN_MAP).astype(float)\n",
    "spreads_long[\"y_abs_bps\"] = spreads_long[\"y_bps\"].abs()\n",
    "\n",
    "# Sample restriction (keep full stacked panel consistent throughout)\n",
    "spreads_long = spreads_long[\n",
    "    (spreads_long[\"date\"] >= CONFIG[\"sample_start\"]) & (spreads_long[\"date\"] <= CONFIG[\"sample_end\"])\n",
    "].copy()\n",
    "\n",
    "# Quick unit/magnitude check by strategy\n",
    "chk = spreads_long.groupby(\"strategy\")[\"y_abs_bps\"].quantile([0.5,0.9,0.99]).unstack()\n",
    "chk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>present</th>\n",
       "      <th>missing_share</th>\n",
       "      <th>n_nonmissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spr_effr</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issu_7_bil</td>\n",
       "      <td>True</td>\n",
       "      <td>0.885535</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issu_14_bil</td>\n",
       "      <td>True</td>\n",
       "      <td>0.885535</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>issu_30_bil</td>\n",
       "      <td>True</td>\n",
       "      <td>0.885535</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOFR</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spr_tgcr</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIX</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HY_OAS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAA10Y</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           var  present  missing_share  n_nonmissing\n",
       "8     spr_effr    False       1.000000             0\n",
       "3   issu_7_bil     True       0.885535            91\n",
       "4  issu_14_bil     True       0.885535            91\n",
       "5  issu_30_bil     True       0.885535            91\n",
       "6         SOFR     True       0.015094           783\n",
       "7     spr_tgcr     True       0.015094           783\n",
       "0          VIX     True       0.001258           794\n",
       "1       HY_OAS     True       0.001258           794\n",
       "2       BAA10Y     True       0.001258           794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>BAA10Y</th>\n",
       "      <th>HY_OAS</th>\n",
       "      <th>SOFR</th>\n",
       "      <th>VIX</th>\n",
       "      <th>issu_14_bil</th>\n",
       "      <th>issu_30_bil</th>\n",
       "      <th>issu_7_bil</th>\n",
       "      <th>spr_tgcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.35</td>\n",
       "      <td>315.0</td>\n",
       "      <td>23.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2.48</td>\n",
       "      <td>5.44</td>\n",
       "      <td>270.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.05</td>\n",
       "      <td>245.0</td>\n",
       "      <td>21.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  BAA10Y  HY_OAS   SOFR    VIX  issu_14_bil  issu_30_bil  \\\n",
       "0 2019-01-01     NaN     NaN    NaN    NaN          NaN          NaN   \n",
       "1 2019-01-02    2.45    5.35  315.0  23.22          NaN          NaN   \n",
       "2 2019-01-03    2.48    5.44  270.0  25.45          NaN          NaN   \n",
       "3 2019-01-04    2.45    5.05  245.0  21.38          NaN          NaN   \n",
       "4 2019-01-07    2.42    4.83  241.0  21.40          NaN          NaN   \n",
       "\n",
       "   issu_7_bil  spr_tgcr  \n",
       "0         NaN       NaN  \n",
       "1         NaN    -500.0  \n",
       "2         NaN       0.0  \n",
       "3         NaN    -200.0  \n",
       "4         NaN    -300.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build daily controls\n",
    "\n",
    "from IPython.display import display\n",
    "#  (prefer intermediate analysis_panel; else raw fallback). All funding rate controls are converted to bps.\n",
    "\n",
    "needed = set(CONFIG[\"direct_controls\"])\n",
    "controls = None\n",
    "\n",
    "# Preferred: intermediate analysis_panel\n",
    "try:\n",
    "    p = resolve_dataset_path(\"analysis_panel\", expected_dir=repo_root / \"data\" / \"intermediate\")\n",
    "    panel = load_any_table(p)\n",
    "    panel[\"date\"] = pd.to_datetime(panel[\"date\"], errors=\"coerce\")\n",
    "    panel[\"date\"] = as_daily_date(panel[\"date\"])\n",
    "    if needed.issubset(set(panel.columns)):\n",
    "        logger.info(\"Using controls from intermediate analysis_panel: %s\", p)\n",
    "        controls = panel[[\"date\", *sorted(needed)]].copy()\n",
    "except Exception as exc:  # noqa: BLE001\n",
    "    logger.warning(\"analysis_panel unavailable/invalid (%s), using raw fallback\", exc)\n",
    "\n",
    "# Fallback: raw sources\n",
    "if controls is None:\n",
    "    fred = load_any_table(resolve_dataset_path(\"controls_vix_creditspreads_fred\", expected_dir=repo_root / \"data\" / \"raw\" / \"event_inputs\"))\n",
    "    fred[\"date\"] = pd.to_datetime(fred[\"date\"], errors=\"coerce\")\n",
    "    fred[\"date\"] = as_daily_date(fred[\"date\"])\n",
    "\n",
    "    try:\n",
    "        repo = load_any_table(resolve_dataset_path(\"repo_rates_combined\", expected_dir=repo_root / \"data\" / \"raw\" / \"event_inputs\"))\n",
    "    except FileNotFoundError:\n",
    "        repo = load_any_table(resolve_dataset_path(\"repo_rates_fred\", expected_dir=repo_root / \"data\" / \"raw\" / \"event_inputs\"))\n",
    "    repo[\"date\"] = pd.to_datetime(repo[\"date\"], errors=\"coerce\")\n",
    "    repo[\"date\"] = as_daily_date(repo[\"date\"])\n",
    "    repo = repo.rename(columns={\"TGCR\": \"tgcr\", \"EFFR\": \"effr\"})\n",
    "\n",
    "    if \"spr_tgcr\" not in repo.columns and {\"SOFR\",\"tgcr\"}.issubset(repo.columns):\n",
    "        repo[\"spr_tgcr\"] = pd.to_numeric(repo[\"tgcr\"], errors=\"coerce\") - pd.to_numeric(repo[\"SOFR\"], errors=\"coerce\")\n",
    "    if \"spr_effr\" not in repo.columns and {\"SOFR\",\"effr\"}.issubset(repo.columns):\n",
    "        repo[\"spr_effr\"] = pd.to_numeric(repo[\"effr\"], errors=\"coerce\") - pd.to_numeric(repo[\"SOFR\"], errors=\"coerce\")\n",
    "\n",
    "    issu = load_any_table(resolve_dataset_path(\"treasury_issuance_by_tenor_fiscaldata\", expected_dir=repo_root / \"data\" / \"raw\" / \"event_inputs\"))\n",
    "    issu[\"date\"] = pd.to_datetime(issu.get(\"issue_date\"), errors=\"coerce\")\n",
    "    issu[\"date\"] = as_daily_date(issu[\"date\"])\n",
    "    issu[\"tenor_bucket\"] = pd.to_numeric(issu[\"tenor_bucket\"], errors=\"coerce\")\n",
    "    issu[\"issuance_amount\"] = pd.to_numeric(issu[\"issuance_amount\"], errors=\"coerce\") / 1e9\n",
    "    d = issu.pivot_table(index=\"date\", columns=\"tenor_bucket\", values=\"issuance_amount\", aggfunc=\"sum\").reset_index()\n",
    "\n",
    "    # robust renaming\n",
    "    rename_map = {}\n",
    "    for col in d.columns:\n",
    "        if col == \"date\":\n",
    "            continue\n",
    "        try:\n",
    "            v = float(col)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if abs(v - 7.0) < 1e-9:\n",
    "            rename_map[col] = \"issu_7_bil\"\n",
    "        elif abs(v - 10.0) < 1e-9:\n",
    "            rename_map[col] = \"issu_10_bil\"\n",
    "        elif abs(v - 14.0) < 1e-9:\n",
    "            rename_map[col] = \"issu_14_bil\"\n",
    "        elif abs(v - 20.0) < 1e-9:\n",
    "            rename_map[col] = \"issu_20_bil\"\n",
    "        elif abs(v - 30.0) < 1e-9:\n",
    "            rename_map[col] = \"issu_30_bil\"\n",
    "    d = d.rename(columns=rename_map)\n",
    "\n",
    "    for c in [\"issu_7_bil\", \"issu_14_bil\", \"issu_30_bil\", \"issu_10_bil\", \"issu_20_bil\"]:\n",
    "        if c not in d.columns:\n",
    "            d[c] = 0.0\n",
    "    if d[\"issu_14_bil\"].fillna(0.0).abs().sum() == 0.0:\n",
    "        d[\"issu_14_bil\"] = d.get(\"issu_10_bil\", 0.0) + d.get(\"issu_20_bil\", 0.0)\n",
    "\n",
    "    for c in [\"issu_7_bil\", \"issu_14_bil\", \"issu_30_bil\"]:\n",
    "        d[c] = pd.to_numeric(d[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    d = d[[\"date\", \"issu_7_bil\", \"issu_14_bil\", \"issu_30_bil\"]]\n",
    "\n",
    "    fred = fred.groupby(\"date\", as_index=False).mean(numeric_only=True)\n",
    "    repo = repo.groupby(\"date\", as_index=False).mean(numeric_only=True)\n",
    "    d    = d.groupby(\"date\", as_index=False).sum(numeric_only=True)\n",
    "\n",
    "    controls = fred.merge(repo, on=\"date\", how=\"outer\").merge(d, on=\"date\", how=\"outer\").sort_values(\"date\")\n",
    "\n",
    "    keep = [\"date\"] + sorted(set(CONFIG[\"direct_controls\"]) & set(controls.columns))\n",
    "    controls = controls[keep].copy()\n",
    "\n",
    "# Coerce numeric + convert funding controls to bps\n",
    "controls[\"date\"] = pd.to_datetime(controls[\"date\"], errors=\"coerce\")\n",
    "controls[\"date\"] = as_daily_date(controls[\"date\"])\n",
    "controls = controls.dropna(subset=[\"date\"])\n",
    "\n",
    "for c in [c for c in CONFIG[\"direct_controls\"] if c in controls.columns]:\n",
    "    controls[c] = pd.to_numeric(controls[c], errors=\"coerce\")\n",
    "\n",
    "# funding-related controls to bps\n",
    "for c in [\"SOFR\",\"spr_tgcr\",\"spr_effr\",\"tgcr\",\"effr\"]:\n",
    "    if c in controls.columns:\n",
    "        controls[c] = _to_bps(controls[c])\n",
    "\n",
    "# ensure unique by date\n",
    "if controls[\"date\"].duplicated().any():\n",
    "    controls = controls.groupby(\"date\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "# sample trim\n",
    "controls = controls[(controls[\"date\"] >= CONFIG[\"sample_start\"]) & (controls[\"date\"] <= CONFIG[\"sample_end\"])].copy()\n",
    "\n",
    "# Missingness report (including absent columns)\n",
    "def missingness_report(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            out.append({\"var\": c, \"present\": False, \"missing_share\": 1.0, \"n_nonmissing\": 0})\n",
    "        else:\n",
    "            s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "            out.append({\"var\": c, \"present\": True, \"missing_share\": float(s.isna().mean()), \"n_nonmissing\": int(s.notna().sum())})\n",
    "    return pd.DataFrame(out).sort_values([\"present\",\"missing_share\"], ascending=[True, False])\n",
    "\n",
    "display(missingness_report(controls, CONFIG[\"direct_controls\"]))\n",
    "controls.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764af4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>BAA10Y</th>\n",
       "      <th>HY_OAS</th>\n",
       "      <th>SOFR</th>\n",
       "      <th>VIX</th>\n",
       "      <th>issu_14_bil</th>\n",
       "      <th>issu_30_bil</th>\n",
       "      <th>issu_7_bil</th>\n",
       "      <th>spr_tgcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.35</td>\n",
       "      <td>315.0</td>\n",
       "      <td>23.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2.48</td>\n",
       "      <td>5.44</td>\n",
       "      <td>270.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.05</td>\n",
       "      <td>245.0</td>\n",
       "      <td>21.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3.01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.09</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.22</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>795 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  BAA10Y  HY_OAS   SOFR    VIX  issu_14_bil  issu_30_bil  \\\n",
       "0   2019-01-01     NaN     NaN    NaN    NaN          NaN          NaN   \n",
       "1   2019-01-02    2.45    5.35  315.0  23.22          NaN          NaN   \n",
       "2   2019-01-03    2.48    5.44  270.0  25.45          NaN          NaN   \n",
       "3   2019-01-04    2.45    5.05  245.0  21.38          NaN          NaN   \n",
       "4   2019-01-07    2.42    4.83  241.0  21.40          NaN          NaN   \n",
       "..         ...     ...     ...    ...    ...          ...          ...   \n",
       "790 2021-12-27    1.86    3.02    5.0  17.68          NaN          NaN   \n",
       "791 2021-12-28    1.86    3.01    5.0  17.54          NaN          NaN   \n",
       "792 2021-12-29    1.85    3.03    5.0  16.95          NaN          NaN   \n",
       "793 2021-12-30    1.85    3.09    5.0  17.33          NaN          NaN   \n",
       "794 2021-12-31    1.85    3.10    5.0  17.22         41.0          0.0   \n",
       "\n",
       "     issu_7_bil  spr_tgcr  \n",
       "0           NaN       NaN  \n",
       "1           NaN    -500.0  \n",
       "2           NaN       0.0  \n",
       "3           NaN    -200.0  \n",
       "4           NaN    -300.0  \n",
       "..          ...       ...  \n",
       "790         NaN       0.0  \n",
       "791         NaN       0.0  \n",
       "792         NaN       0.0  \n",
       "793         NaN       0.0  \n",
       "794         0.0       0.0  \n",
       "\n",
       "[795 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>strategy</th>\n",
       "      <th>series_id</th>\n",
       "      <th>tenor</th>\n",
       "      <th>treasury_based</th>\n",
       "      <th>y_raw_bps</th>\n",
       "      <th>y_bps</th>\n",
       "      <th>y_abs_bps</th>\n",
       "      <th>VIX</th>\n",
       "      <th>HY_OAS</th>\n",
       "      <th>BAA10Y</th>\n",
       "      <th>issu_7_bil</th>\n",
       "      <th>issu_14_bil</th>\n",
       "      <th>issu_30_bil</th>\n",
       "      <th>SOFR</th>\n",
       "      <th>spr_tgcr</th>\n",
       "      <th>relief</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2658.066667</td>\n",
       "      <td>-2658.066667</td>\n",
       "      <td>2658.066667</td>\n",
       "      <td>23.22</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2895.222222</td>\n",
       "      <td>-2895.222222</td>\n",
       "      <td>2895.222222</td>\n",
       "      <td>25.45</td>\n",
       "      <td>5.44</td>\n",
       "      <td>2.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2895.222222</td>\n",
       "      <td>-2895.222222</td>\n",
       "      <td>2895.222222</td>\n",
       "      <td>21.38</td>\n",
       "      <td>5.05</td>\n",
       "      <td>2.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2702.577778</td>\n",
       "      <td>-2702.577778</td>\n",
       "      <td>2702.577778</td>\n",
       "      <td>21.40</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2431.000000</td>\n",
       "      <td>-2431.000000</td>\n",
       "      <td>2431.000000</td>\n",
       "      <td>20.47</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      strategy        series_id tenor  treasury_based  \\\n",
       "0 2019-01-02  ust_spot_fut  ust_spot_fut_2y     2               1   \n",
       "1 2019-01-03  ust_spot_fut  ust_spot_fut_2y     2               1   \n",
       "2 2019-01-04  ust_spot_fut  ust_spot_fut_2y     2               1   \n",
       "3 2019-01-07  ust_spot_fut  ust_spot_fut_2y     2               1   \n",
       "4 2019-01-08  ust_spot_fut  ust_spot_fut_2y     2               1   \n",
       "\n",
       "     y_raw_bps        y_bps    y_abs_bps    VIX  HY_OAS  BAA10Y  issu_7_bil  \\\n",
       "0  2658.066667 -2658.066667  2658.066667  23.22    5.35    2.45         NaN   \n",
       "1  2895.222222 -2895.222222  2895.222222  25.45    5.44    2.48         NaN   \n",
       "2  2895.222222 -2895.222222  2895.222222  21.38    5.05    2.45         NaN   \n",
       "3  2702.577778 -2702.577778  2702.577778  21.40    4.83    2.42         NaN   \n",
       "4  2431.000000 -2431.000000  2431.000000  20.47    4.65    2.39         NaN   \n",
       "\n",
       "   issu_14_bil  issu_30_bil   SOFR  spr_tgcr  relief  \n",
       "0          NaN          NaN  315.0    -500.0       0  \n",
       "1          NaN          NaN  270.0       0.0       0  \n",
       "2          NaN          NaN  245.0    -200.0       0  \n",
       "3          NaN          NaN  241.0    -300.0       0  \n",
       "4          NaN          NaN  242.0    -200.0       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge stacked outcomes with controls (m:1 by date); construct relief indicator; persist analysis panel\n",
    "\n",
    "# keep only needed controls for merge\n",
    "use_controls = [c for c in CONFIG[\"direct_controls\"] if c in controls.columns]\n",
    "controls_use = controls[[\"date\", *use_controls]].copy()\n",
    "\n",
    "# validate uniqueness\n",
    "if controls_use[\"date\"].duplicated().any():\n",
    "    raise RuntimeError(\"controls_use is not unique by date after cleaning (expected m:1 merge).\")\n",
    "\n",
    "panel_long = spreads_long.merge(controls_use, on=\"date\", how=\"left\", validate=\"m:1\")\n",
    "\n",
    "# numeric coercions for controls\n",
    "for c in use_controls:\n",
    "    panel_long[c] = pd.to_numeric(panel_long[c], errors=\"coerce\")\n",
    "\n",
    "# Relief indicator (full-sample estimand)\n",
    "panel_long[\"relief\"] = ((panel_long[\"date\"] >= \"2020-04-01\") & (panel_long[\"date\"] <= \"2021-03-31\")).astype(int)\n",
    "\n",
    "# Ensure types\n",
    "panel_long[\"treasury_based\"] = pd.to_numeric(panel_long[\"treasury_based\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "panel_long[\"strategy\"] = panel_long[\"strategy\"].astype(\"category\")\n",
    "# Make parquet-safe dtypes\n",
    "panel_long[\"tenor\"] = panel_long[\"tenor\"].astype(str)\n",
    "panel_long[\"series_id\"] = panel_long[\"series_id\"].astype(str)\n",
    "panel_long[\"strategy\"] = panel_long[\"strategy\"].astype(str)\n",
    "panel_long.to_parquet(run_dir / \"data\" / \"panel_long.parquet\", index=False)\n",
    "panel_long.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>series_id</th>\n",
       "      <th>tenor</th>\n",
       "      <th>regime</th>\n",
       "      <th>N_days</th>\n",
       "      <th>mean_W</th>\n",
       "      <th>median_W</th>\n",
       "      <th>p5_W</th>\n",
       "      <th>p95_W</th>\n",
       "      <th>mean_absW</th>\n",
       "      <th>share_absW_le_5</th>\n",
       "      <th>share_absW_le_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_10y</td>\n",
       "      <td>10</td>\n",
       "      <td>post</td>\n",
       "      <td>192</td>\n",
       "      <td>1005.869878</td>\n",
       "      <td>891.994444</td>\n",
       "      <td>278.492778</td>\n",
       "      <td>2010.622500</td>\n",
       "      <td>1016.770573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_10y</td>\n",
       "      <td>10</td>\n",
       "      <td>pre</td>\n",
       "      <td>314</td>\n",
       "      <td>-2153.668507</td>\n",
       "      <td>-2337.094444</td>\n",
       "      <td>-4401.122778</td>\n",
       "      <td>694.347222</td>\n",
       "      <td>2470.173107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_10y</td>\n",
       "      <td>10</td>\n",
       "      <td>relief</td>\n",
       "      <td>251</td>\n",
       "      <td>-539.043161</td>\n",
       "      <td>-609.700000</td>\n",
       "      <td>-1603.916667</td>\n",
       "      <td>767.694444</td>\n",
       "      <td>817.458123</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>post</td>\n",
       "      <td>192</td>\n",
       "      <td>998.707697</td>\n",
       "      <td>804.500000</td>\n",
       "      <td>-318.182778</td>\n",
       "      <td>2739.091667</td>\n",
       "      <td>1256.464294</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>pre</td>\n",
       "      <td>314</td>\n",
       "      <td>-2540.439048</td>\n",
       "      <td>-2426.800000</td>\n",
       "      <td>-4301.139444</td>\n",
       "      <td>-958.383333</td>\n",
       "      <td>2563.329848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_2y</td>\n",
       "      <td>2</td>\n",
       "      <td>relief</td>\n",
       "      <td>251</td>\n",
       "      <td>-578.769987</td>\n",
       "      <td>-599.622222</td>\n",
       "      <td>-1611.050000</td>\n",
       "      <td>944.900000</td>\n",
       "      <td>755.623904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_5y</td>\n",
       "      <td>5</td>\n",
       "      <td>post</td>\n",
       "      <td>192</td>\n",
       "      <td>549.956655</td>\n",
       "      <td>527.255556</td>\n",
       "      <td>-36.631667</td>\n",
       "      <td>1276.400000</td>\n",
       "      <td>578.954225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_5y</td>\n",
       "      <td>5</td>\n",
       "      <td>pre</td>\n",
       "      <td>314</td>\n",
       "      <td>-2629.634820</td>\n",
       "      <td>-2626.944444</td>\n",
       "      <td>-4377.473333</td>\n",
       "      <td>-664.455556</td>\n",
       "      <td>2636.795188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>ust_spot_fut_5y</td>\n",
       "      <td>5</td>\n",
       "      <td>relief</td>\n",
       "      <td>251</td>\n",
       "      <td>-625.344444</td>\n",
       "      <td>-650.488889</td>\n",
       "      <td>-1779.333333</td>\n",
       "      <td>593.300000</td>\n",
       "      <td>767.842010</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       strategy         series_id tenor  regime  N_days       mean_W  \\\n",
       "2  ust_spot_fut  ust_spot_fut_10y    10    post     192  1005.869878   \n",
       "0  ust_spot_fut  ust_spot_fut_10y    10     pre     314 -2153.668507   \n",
       "1  ust_spot_fut  ust_spot_fut_10y    10  relief     251  -539.043161   \n",
       "5  ust_spot_fut   ust_spot_fut_2y     2    post     192   998.707697   \n",
       "3  ust_spot_fut   ust_spot_fut_2y     2     pre     314 -2540.439048   \n",
       "4  ust_spot_fut   ust_spot_fut_2y     2  relief     251  -578.769987   \n",
       "8  ust_spot_fut   ust_spot_fut_5y     5    post     192   549.956655   \n",
       "6  ust_spot_fut   ust_spot_fut_5y     5     pre     314 -2629.634820   \n",
       "7  ust_spot_fut   ust_spot_fut_5y     5  relief     251  -625.344444   \n",
       "\n",
       "      median_W         p5_W        p95_W    mean_absW  share_absW_le_5  \\\n",
       "2   891.994444   278.492778  2010.622500  1016.770573         0.000000   \n",
       "0 -2337.094444 -4401.122778   694.347222  2470.173107         0.000000   \n",
       "1  -609.700000 -1603.916667   767.694444   817.458123         0.003984   \n",
       "5   804.500000  -318.182778  2739.091667  1256.464294         0.005208   \n",
       "3 -2426.800000 -4301.139444  -958.383333  2563.329848         0.000000   \n",
       "4  -599.622222 -1611.050000   944.900000   755.623904         0.000000   \n",
       "8   527.255556   -36.631667  1276.400000   578.954225         0.000000   \n",
       "6 -2626.944444 -4377.473333  -664.455556  2636.795188         0.000000   \n",
       "7  -650.488889 -1779.333333   593.300000   767.842010         0.003984   \n",
       "\n",
       "   share_absW_le_10  \n",
       "2          0.000000  \n",
       "0          0.000000  \n",
       "1          0.003984  \n",
       "5          0.005208  \n",
       "3          0.000000  \n",
       "4          0.000000  \n",
       "8          0.000000  \n",
       "6          0.000000  \n",
       "7          0.007968  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 1 (paper-ready): Arbitrage spread levels by strategy × tenor × regime (includes near-zero shares)\n",
    "\n",
    "regimes = {\n",
    "    \"pre\": (pd.Timestamp(\"2019-01-01\"), pd.Timestamp(\"2020-03-31\")),\n",
    "    \"relief\": (pd.Timestamp(\"2020-04-01\"), pd.Timestamp(\"2021-03-31\")),\n",
    "    \"post\": (pd.Timestamp(\"2021-04-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "}\n",
    "deltas = CONFIG[\"near_zero_deltas\"]\n",
    "\n",
    "rows = []\n",
    "# for (strategy, tenor), g in panel_long.groupby([\"strategy\",\"tenor\"]):\n",
    "# for series_id, g in panel_long.groupby([\"series_id\"]): # for eq_INDU\n",
    "# for (strategy, tenor), g in panel_long.groupby([\"strategy\",\"tenor\"]):\n",
    "for series_id, g in panel_long.groupby(\"series_id\", dropna=False):\n",
    "    g = g.sort_values(\"date\")\n",
    "    # Derive identifiers from the group (robust for single-strategy runs)\n",
    "    strategy = (g[\"strategy\"].dropna().iloc[0]\n",
    "                if \"strategy\" in g.columns and not g[\"strategy\"].dropna().empty\n",
    "                else \"unknown\")\n",
    "    tenor = (g[\"tenor\"].dropna().iloc[0]\n",
    "            if \"tenor\" in g.columns and not g[\"tenor\"].dropna().empty\n",
    "            else \"NA\")\n",
    "    for regime, (start, end) in regimes.items():\n",
    "        sub = g[(g[\"date\"] >= start) & (g[\"date\"] <= end)].copy()\n",
    "        y = pd.to_numeric(sub[\"y_bps\"], errors=\"coerce\")\n",
    "        ya = pd.to_numeric(sub[\"y_abs_bps\"], errors=\"coerce\")\n",
    "        if ya.dropna().empty:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"strategy\": str(strategy),\n",
    "            \"series_id\": str(series_id),\n",
    "            \"tenor\": str(tenor),\n",
    "            \"regime\": regime,\n",
    "            \"N_days\": int(ya.notna().sum()),\n",
    "            \"mean_W\": float(y.mean()),\n",
    "            \"median_W\": float(y.median()),\n",
    "            \"p5_W\": float(y.quantile(0.05)),\n",
    "            \"p95_W\": float(y.quantile(0.95)),\n",
    "            \"mean_absW\": float(ya.mean()),\n",
    "        }\n",
    "        for d0 in deltas:\n",
    "            row[f\"share_absW_le_{int(d0)}\"] = float((ya <= d0).mean())\n",
    "        rows.append(row)\n",
    "\n",
    "# table1 = pd.DataFrame(rows).sort_values([\"strategy\",\"tenor\",\"regime\"])\n",
    "table1 = pd.DataFrame(rows).sort_values([\"strategy\",\"series_id\",\"tenor\",\"regime\"])\n",
    "# Replace prior summary_stats.csv with this paper-ready Table 1\n",
    "table1.to_csv(run_dir / \"tables\" / \"summary_stats.csv\", index=False)\n",
    "table1.to_csv(run_dir / \"tables\" / \"table1_levels_nearzero.csv\", index=False)\n",
    "\n",
    "table1.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\83827688.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return out.groupby(group_col, group_keys=False).apply(_apply)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\83827688.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return out.groupby(group_col, group_keys=False).apply(_apply)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\83827688.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return out.groupby(group_col, group_keys=False).apply(_apply)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>window_td</th>\n",
       "      <th>strategy</th>\n",
       "      <th>spec</th>\n",
       "      <th>coef_post</th>\n",
       "      <th>se_post</th>\n",
       "      <th>N</th>\n",
       "      <th>N_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>20</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>-6030.996424</td>\n",
       "      <td>3012.460362</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>20</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>50.082248</td>\n",
       "      <td>23.344478</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>60</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>-580.165895</td>\n",
       "      <td>400.486507</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>60</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>-1008.389613</td>\n",
       "      <td>855.274289</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>20</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>502.261085</td>\n",
       "      <td>56.309133</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        event  window_td      strategy    spec    coef_post      se_post   N  \\\n",
       "0  2020-04-01         20  ust_spot_fut   TOTAL -6030.996424  3012.460362  15   \n",
       "1  2020-04-01         20  ust_spot_fut  DIRECT    50.082248    23.344478  15   \n",
       "2  2020-04-01         60  ust_spot_fut   TOTAL  -580.165895   400.486507  42   \n",
       "3  2020-04-01         60  ust_spot_fut  DIRECT -1008.389613   855.274289  42   \n",
       "4  2021-03-19         20  ust_spot_fut   TOTAL   502.261085    56.309133  18   \n",
       "\n",
       "   N_dates  \n",
       "0       15  \n",
       "1       15  \n",
       "2       42  \n",
       "3       42  \n",
       "4       18  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer 1: event-window jump regressions (trading-day event time) + pooled interactions\n",
    "\n",
    "jump_rows = []\n",
    "models = []\n",
    "meta = []\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def assign_bins(df: pd.DataFrame, bins: list[tuple[int,int]], col=\"event_time\", outcol=\"bin\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign each row to a bin label like 'bin_[a,b]' based on integer event_time.\n",
    "    bins is a list of (lo, hi) inclusive endpoints.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    et = pd.to_numeric(out[col], errors=\"coerce\")\n",
    "    out[outcol] = np.nan\n",
    "    for lo, hi in bins:\n",
    "        m = (et >= lo) & (et <= hi)\n",
    "        out.loc[m, outcol] = f\"bin_[{lo},{hi}]\"\n",
    "    return out\n",
    "\n",
    "lo, hi = CONFIG[\"event_range\"]\n",
    "\n",
    "for event in CONFIG[\"events\"]:\n",
    "    \n",
    "    work = add_event_time_trading(panel_long, event, group_col=\"series_id\")\n",
    "    work = work[work[\"event_time\"].between(lo, hi)].copy()\n",
    "\n",
    "    for W in CONFIG[\"windows\"]:\n",
    "        subW = work[work[\"event_time\"].between(-W, W)].copy()\n",
    "        subW[\"post\"] = (subW[\"event_time\"] >= 0).astype(int)\n",
    "\n",
    "        # (A) by-strategy pooled within strategy (series FE) — TOTAL vs DIRECT\n",
    "        for strategy in sorted(subW[\"strategy\"].astype(str).unique().tolist()):\n",
    "            g = subW[subW[\"strategy\"].astype(str) == strategy].copy()\n",
    "            if g.empty:\n",
    "                continue\n",
    "            for spec, controls_set in [(\"TOTAL\", CONFIG[\"total_controls\"]), (\"DIRECT\", CONFIG[\"direct_controls\"])]:\n",
    "                robust, reg = run_pooled_jump(g, y_col=\"y_abs_bps\", controls=controls_set, fe_col=\"series_id\", interact_treasury=False)\n",
    "                # extract post coefficient\n",
    "                if \"post\" in robust.model.exog_names:\n",
    "                    i = robust.model.exog_names.index(\"post\")\n",
    "                    jump_rows.append({\n",
    "                        \"event\": event, \"window_td\": W, \"strategy\": strategy, \"spec\": spec,\n",
    "                        \"coef_post\": float(robust.params[i]), \"se_post\": float(robust.bse[i]),\n",
    "                        \"N\": int(robust.nobs), \"N_dates\": int(reg[\"post\"].shape[0])  # obs count; dates handled below if needed\n",
    "                    })\n",
    "\n",
    "        # (B) FULL pooled across strategies with post × treasury_based interaction (used for Table 2)\n",
    "        for spec, controls_set in [(\"TOTAL\", CONFIG[\"total_controls\"]), (\"DIRECT\", CONFIG[\"direct_controls\"])]:\n",
    "            robust_all, reg_all = run_pooled_jump(subW, y_col=\"y_abs_bps\", controls=controls_set, fe_col=\"series_id\", interact_treasury=True)\n",
    "            models.append(robust_all)\n",
    "            meta.append({\n",
    "                \"event\": event,\n",
    "                \"spec\": spec,\n",
    "                \"window\": f\"[-{W},+{W}] trading days\",\n",
    "                \"funding_controls\": \"Yes\" if spec == \"DIRECT\" else \"No\",\n",
    "                \"n_obs\": int(robust_all.nobs),\n",
    "                \"n_dates\": int(pd.to_datetime(reg_all.index).nunique()) if hasattr(reg_all.index, \"nunique\") else np.nan,\n",
    "            })\n",
    "\n",
    "jump_by_strategy = pd.DataFrame(jump_rows)\n",
    "jump_by_strategy.to_csv(run_dir / \"tables\" / \"jump_by_strategy.csv\", index=False)\n",
    "jump_by_strategy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\83827688.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return out.groupby(group_col, group_keys=False).apply(_apply)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\83827688.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return out.groupby(group_col, group_keys=False).apply(_apply)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_18176\\83827688.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return out.groupby(group_col, group_keys=False).apply(_apply)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>strategy</th>\n",
       "      <th>spec</th>\n",
       "      <th>ref_bin</th>\n",
       "      <th>bin</th>\n",
       "      <th>bin_mid</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>bin_[-20,-1]</td>\n",
       "      <td>bin_[-60,-41]</td>\n",
       "      <td>-50.5</td>\n",
       "      <td>-1671.401500</td>\n",
       "      <td>701.385315</td>\n",
       "      <td>-3046.116718</td>\n",
       "      <td>-296.686282</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>bin_[-20,-1]</td>\n",
       "      <td>bin_[-40,-21]</td>\n",
       "      <td>-30.5</td>\n",
       "      <td>-1999.563153</td>\n",
       "      <td>662.688764</td>\n",
       "      <td>-3298.433131</td>\n",
       "      <td>-700.693175</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>bin_[-20,-1]</td>\n",
       "      <td>bin_[0,0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-632.225279</td>\n",
       "      <td>719.135746</td>\n",
       "      <td>-2041.731342</td>\n",
       "      <td>777.280783</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>bin_[-20,-1]</td>\n",
       "      <td>bin_[1,20]</td>\n",
       "      <td>10.5</td>\n",
       "      <td>-391.097405</td>\n",
       "      <td>354.960443</td>\n",
       "      <td>-1086.819874</td>\n",
       "      <td>304.625064</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>bin_[-20,-1]</td>\n",
       "      <td>bin_[21,40]</td>\n",
       "      <td>30.5</td>\n",
       "      <td>-172.722089</td>\n",
       "      <td>437.620717</td>\n",
       "      <td>-1030.458695</td>\n",
       "      <td>685.014517</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        event      strategy   spec       ref_bin            bin  bin_mid  \\\n",
       "0  2020-04-01  ust_spot_fut  TOTAL  bin_[-20,-1]  bin_[-60,-41]    -50.5   \n",
       "1  2020-04-01  ust_spot_fut  TOTAL  bin_[-20,-1]  bin_[-40,-21]    -30.5   \n",
       "2  2020-04-01  ust_spot_fut  TOTAL  bin_[-20,-1]      bin_[0,0]      0.0   \n",
       "3  2020-04-01  ust_spot_fut  TOTAL  bin_[-20,-1]     bin_[1,20]     10.5   \n",
       "4  2020-04-01  ust_spot_fut  TOTAL  bin_[-20,-1]    bin_[21,40]     30.5   \n",
       "\n",
       "      estimate          se       ci_low     ci_high  nobs  \n",
       "0 -1671.401500  701.385315 -3046.116718 -296.686282   363  \n",
       "1 -1999.563153  662.688764 -3298.433131 -700.693175   363  \n",
       "2  -632.225279  719.135746 -2041.731342  777.280783   363  \n",
       "3  -391.097405  354.960443 -1086.819874  304.625064   363  \n",
       "4  -172.722089  437.620717 -1030.458695  685.014517   363  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>spec</th>\n",
       "      <th>ref_bin</th>\n",
       "      <th>bin</th>\n",
       "      <th>bin_mid</th>\n",
       "      <th>term</th>\n",
       "      <th>estimate</th>\n",
       "      <th>se</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [event, spec, ref_bin, bin, bin_mid, term, estimate, se, ci_low, ci_high, nobs]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Layer 1: binned event-study paths by strategy (trading-day event time) + pooled treasury-based interactions\n",
    "# Robust: (i) always constructs reg with 'bin'; (ii) chooses valid pre-bin baseline; (iii) preserves impact day;\n",
    "# (iv) never double-adds controls; (v) no silent 0-fill for missing bins.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "bins = CONFIG[\"event_bins\"]\n",
    "lo, hi = CONFIG[\"event_range\"]\n",
    "\n",
    "rows = []\n",
    "rows_pooled = []\n",
    "\n",
    "def _bin_mid(label: str) -> float:\n",
    "    m = re.search(r\"\\[\\s*(-?\\d+)\\s*,\\s*(-?\\d+)\\s*\\]\", str(label))\n",
    "    if not m:\n",
    "        return np.nan\n",
    "    a, b = int(m.group(1)), int(m.group(2))\n",
    "    return 0.5 * (a + b)\n",
    "\n",
    "def choose_ref_bin(reg: pd.DataFrame, default=\"bin_[-20,-1]\") -> str:\n",
    "    \"\"\"Pick a pre-event reference bin that exists in THIS regression sample.\"\"\"\n",
    "    b = reg[\"bin\"].astype(str)\n",
    "    if default in set(b.unique()):\n",
    "        return default\n",
    "\n",
    "    def parse_hi(lbl: str):\n",
    "        m = re.search(r\"\\[\\s*(-?\\d+)\\s*,\\s*(-?\\d+)\\s*\\]\", lbl)\n",
    "        return int(m.group(2)) if m else None\n",
    "\n",
    "    # candidate pre bins: upper endpoint <= -1\n",
    "    cand = []\n",
    "    for lbl in b.unique():\n",
    "        hi_ = parse_hi(str(lbl))\n",
    "        if hi_ is not None and hi_ <= -1:\n",
    "            cand.append((str(lbl), int((b == lbl).sum()), hi_))\n",
    "\n",
    "    if not cand:\n",
    "        raise RuntimeError(\"No pre-event bins available after dropna(); cannot choose a baseline bin.\")\n",
    "\n",
    "    # most frequent, tie-breaker closest to -1\n",
    "    cand.sort(key=lambda x: (-x[1], abs(x[2] - (-1))))\n",
    "    return cand[0][0]\n",
    "\n",
    "def drop_controls_that_kill_impact(df: pd.DataFrame, controls: list[str]) -> list[str]:\n",
    "    \"\"\"Keep only controls that do not eliminate ALL impact-bin observations (event_time==0).\"\"\"\n",
    "    if \"event_time\" not in df.columns:\n",
    "        return controls\n",
    "    impact = df[\"event_time\"] == 0\n",
    "    if int(impact.sum()) == 0:\n",
    "        return controls\n",
    "\n",
    "    keep = []\n",
    "    for c in controls:\n",
    "        if c not in df.columns:\n",
    "            continue\n",
    "        # must have at least one non-missing value on impact day somewhere in the sample\n",
    "        if df.loc[impact, c].notna().any():\n",
    "            keep.append(c)\n",
    "    return keep\n",
    "\n",
    "for event in CONFIG[\"events\"]:\n",
    "    work = add_event_time_trading(panel_long, event, group_col=\"series_id\")\n",
    "    work = work[work[\"event_time\"].between(lo, hi)].copy()\n",
    "\n",
    "    # create bin labels (categorical) once, on work\n",
    "    work[\"bin\"] = bin_event_time(work[\"event_time\"], bins)\n",
    "\n",
    "    # -----------------------------\n",
    "    # (A) pooled bin × treasury_based interactions\n",
    "    # -----------------------------\n",
    "    for spec, controls_set in [(\"TOTAL\", CONFIG[\"total_controls\"]), (\"DIRECT\", CONFIG[\"direct_controls\"])]:\n",
    "        use_controls = [c for c in controls_set if c in work.columns]\n",
    "        use_controls = drop_controls_that_kill_impact(work, use_controls)\n",
    "\n",
    "        base_cols = [\"y_abs_bps\", \"bin\", \"series_id\", \"treasury_based\"]\n",
    "        reg_cols = base_cols + use_controls\n",
    "        reg = work[reg_cols].dropna().copy()\n",
    "\n",
    "        # Ensure bin exists and is string-labeled for parsing & baseline selection\n",
    "        reg[\"bin\"] = reg[\"bin\"].astype(str)\n",
    "\n",
    "        n_impact = int((reg[\"bin\"] == \"bin_[0,0]\").sum())\n",
    "        if n_impact == 0:\n",
    "            # hard fail with diagnostics (this is the root cause of bogus 0/0SE paths)\n",
    "            impact_before = int((work[\"event_time\"] == 0).sum())\n",
    "            raise RuntimeError(\n",
    "                f\"[{event} | pooled | {spec}] bin_[0,0] has 0 obs after dropna(). \"\n",
    "                f\"Impact rows before dropna: {impact_before}. \"\n",
    "                f\"Controls used: {use_controls}. \"\n",
    "                \"This means impact day is being dropped (missing y or missing controls).\"\n",
    "            )\n",
    "\n",
    "        ref_bin_local = choose_ref_bin(reg, default=\"bin_[-20,-1]\")\n",
    "\n",
    "        # enforce baseline as ref_bin_local (so bin_[0,0] is estimated, not omitted)\n",
    "        bins_present = list(dict.fromkeys(reg[\"bin\"].tolist()))\n",
    "        bins_order = [ref_bin_local] + [b for b in bins_present if b != ref_bin_local]\n",
    "        reg[\"bin\"] = pd.Categorical(reg[\"bin\"], categories=bins_order, ordered=True)\n",
    "\n",
    "        reg = sanitize_for_patsy(reg, category_cols=[\"bin\", \"series_id\"])\n",
    "\n",
    "        rhs = f\"C(bin, Treatment(reference='{ref_bin_local}')) + C(series_id)\"\n",
    "        rhs += f\" + C(bin, Treatment(reference='{ref_bin_local}')):treasury_based\"\n",
    "        if use_controls:\n",
    "            rhs += \" + \" + \" + \".join(use_controls)\n",
    "\n",
    "        res = ols(f\"y_abs_bps ~ {rhs}\", data=reg).fit()\n",
    "        robust = res.get_robustcov_results(cov_type=\"HAC\", maxlags=CONFIG[\"hac_lags_daily\"])\n",
    "\n",
    "        # store bin×treasury interaction terms with parsed bin label\n",
    "        for name, est, se in zip(robust.model.exog_names, robust.params, robust.bse):\n",
    "            if \"treasury_based\" in name and \"C(bin\" in name and \"Treatment\" in name:\n",
    "                m = re.search(r\"T\\.(bin_\\[.*?\\])\", name)\n",
    "                if not m:\n",
    "                    continue\n",
    "                lab = m.group(1)\n",
    "                rows_pooled.append({\n",
    "                    \"event\": event,\n",
    "                    \"spec\": spec,\n",
    "                    \"ref_bin\": ref_bin_local,\n",
    "                    \"bin\": lab,\n",
    "                    \"bin_mid\": _bin_mid(lab),\n",
    "                    \"term\": name,\n",
    "                    \"estimate\": float(est),\n",
    "                    \"se\": float(se),\n",
    "                    \"ci_low\": float(est - 1.96 * se),\n",
    "                    \"ci_high\": float(est + 1.96 * se),\n",
    "                    \"nobs\": int(robust.nobs),\n",
    "                })\n",
    "\n",
    "    # -----------------------------\n",
    "    # (B) by-strategy binned paths (TOTAL vs DIRECT overlay)\n",
    "    # -----------------------------\n",
    "    for strategy in sorted(work[\"strategy\"].astype(str).unique().tolist()):\n",
    "        g = work[work[\"strategy\"].astype(str) == strategy].copy()\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        series_by_spec = {}\n",
    "\n",
    "        for spec, controls_set in [(\"TOTAL\", CONFIG[\"total_controls\"]), (\"DIRECT\", CONFIG[\"direct_controls\"])]:\n",
    "            use_controls = [c for c in controls_set if c in g.columns]\n",
    "            use_controls = drop_controls_that_kill_impact(g, use_controls)\n",
    "\n",
    "            reg_cols = [\"y_abs_bps\", \"bin\", \"series_id\"] + use_controls\n",
    "            reg = g[reg_cols].dropna().copy()\n",
    "\n",
    "            reg[\"bin\"] = reg[\"bin\"].astype(str)\n",
    "            n_impact = int((reg[\"bin\"] == \"bin_[0,0]\").sum())\n",
    "            if n_impact == 0:\n",
    "                impact_before = int((g[\"event_time\"] == 0).sum())\n",
    "                raise RuntimeError(\n",
    "                    f\"[{event} | {strategy} | {spec}] bin_[0,0] has 0 obs after dropna(). \"\n",
    "                    f\"Impact rows before dropna: {impact_before}. Controls used: {use_controls}.\"\n",
    "                )\n",
    "\n",
    "            ref_bin_local = choose_ref_bin(reg, default=\"bin_[-20,-1]\")\n",
    "\n",
    "            bins_present = list(dict.fromkeys(reg[\"bin\"].tolist()))\n",
    "            bins_order = [ref_bin_local] + [b for b in bins_present if b != ref_bin_local]\n",
    "            reg[\"bin\"] = pd.Categorical(reg[\"bin\"], categories=bins_order, ordered=True)\n",
    "\n",
    "            reg = sanitize_for_patsy(reg, category_cols=[\"bin\", \"series_id\"])\n",
    "\n",
    "            rhs = f\"C(bin, Treatment(reference='{ref_bin_local}')) + C(series_id)\"\n",
    "            if use_controls:\n",
    "                rhs += \" + \" + \" + \".join(use_controls)\n",
    "\n",
    "            res = ols(f\"y_abs_bps ~ {rhs}\", data=reg).fit()\n",
    "            robust = res.get_robustcov_results(cov_type=\"HAC\", maxlags=CONFIG[\"hac_lags_daily\"])\n",
    "\n",
    "            out = []\n",
    "            for name, est, se in zip(robust.model.exog_names, robust.params, robust.bse):\n",
    "                if \"C(bin\" in name and \"Treatment\" in name and \"series_id\" not in name and \"treasury_based\" not in name:\n",
    "                    m = re.search(r\"T\\.(bin_\\[.*?\\])\", name)\n",
    "                    if not m:\n",
    "                        continue\n",
    "                    lab = m.group(1)\n",
    "                    out.append({\n",
    "                        \"event\": event,\n",
    "                        \"strategy\": strategy,\n",
    "                        \"spec\": spec,\n",
    "                        \"ref_bin\": ref_bin_local,\n",
    "                        \"bin\": lab,\n",
    "                        \"bin_mid\": _bin_mid(lab),\n",
    "                        \"estimate\": float(est),\n",
    "                        \"se\": float(se),\n",
    "                        \"ci_low\": float(est - 1.96 * se),\n",
    "                        \"ci_high\": float(est + 1.96 * se),\n",
    "                        \"nobs\": int(robust.nobs),\n",
    "                    })\n",
    "\n",
    "            df_out = pd.DataFrame(out).sort_values(\"bin_mid\")\n",
    "            series_by_spec[spec] = df_out\n",
    "            rows.append(df_out)\n",
    "\n",
    "        # plot overlay\n",
    "        if series_by_spec:\n",
    "            fig, ax = plt.subplots(figsize=(8, 4))\n",
    "            for spec, dfp in series_by_spec.items():\n",
    "                if dfp.empty:\n",
    "                    continue\n",
    "                x = dfp[\"bin_mid\"].to_numpy()\n",
    "                ax.plot(x, dfp[\"estimate\"], marker=\"o\", label=spec)\n",
    "                ax.fill_between(x, dfp[\"ci_low\"], dfp[\"ci_high\"], alpha=0.15)\n",
    "            ax.axhline(0, color=\"black\", lw=1)\n",
    "            ax.axvline(0, color=\"black\", ls=\"--\", lw=1)\n",
    "            ax.set_title(f\"{strategy}: binned event study around {event} (DV=|spread|, bps)\")\n",
    "            ax.set_xlabel(\"Event time (bin midpoint, trading days)\")\n",
    "            ax.set_ylabel(\"Effect relative to pre-event ref bin (bps)\")\n",
    "            ax.legend()\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(run_dir / \"figures\" / f\"event_path_{strategy}_{event}_overlay.png\", dpi=150)\n",
    "            plt.close(fig)\n",
    "\n",
    "# --- Write strategy paths (always safe) ---\n",
    "event_paths = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(\n",
    "    columns=[\"event\",\"strategy\",\"spec\",\"ref_bin\",\"bin\",\"bin_mid\",\"estimate\",\"se\",\"ci_low\",\"ci_high\",\"nobs\"]\n",
    ")\n",
    "event_paths.to_csv(run_dir / \"tables\" / \"eventstudy_paths_by_strategy.csv\", index=False)\n",
    "\n",
    "# --- Write pooled bin×treasury interactions (robust to empty/malformed extraction) ---\n",
    "POOLED_COLS = [\"event\",\"spec\",\"ref_bin\",\"bin\",\"bin_mid\",\"term\",\"estimate\",\"se\",\"ci_low\",\"ci_high\",\"nobs\"]\n",
    "\n",
    "if not rows_pooled:\n",
    "    pooled_bin_int = pd.DataFrame(columns=POOLED_COLS)\n",
    "else:\n",
    "    pooled_bin_int = pd.DataFrame(rows_pooled)\n",
    "\n",
    "    # ensure required columns exist even if extraction produced partial dicts\n",
    "    for c in POOLED_COLS:\n",
    "        if c not in pooled_bin_int.columns:\n",
    "            pooled_bin_int[c] = np.nan\n",
    "\n",
    "    # coerce sort keys\n",
    "    pooled_bin_int[\"event\"] = pooled_bin_int[\"event\"].astype(str)\n",
    "    pooled_bin_int[\"spec\"] = pooled_bin_int[\"spec\"].astype(str)\n",
    "    pooled_bin_int[\"bin_mid\"] = pd.to_numeric(pooled_bin_int[\"bin_mid\"], errors=\"coerce\")\n",
    "\n",
    "    pooled_bin_int = pooled_bin_int.sort_values([\"event\",\"spec\",\"bin_mid\"], kind=\"mergesort\")\n",
    "\n",
    "pooled_bin_int.to_csv(run_dir / \"tables\" / \"eventstudy_pooled_binXtreasury.csv\", index=False)\n",
    "\n",
    "# show something useful\n",
    "display(event_paths.head())\n",
    "display(pooled_bin_int.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 12, but rank is 10\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 12, but rank is 10\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 12, but rank is 10\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>spec</th>\n",
       "      <th>window</th>\n",
       "      <th>term</th>\n",
       "      <th>coef</th>\n",
       "      <th>se</th>\n",
       "      <th>n_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post</td>\n",
       "      <td>-290.082948</td>\n",
       "      <td>200.243254</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post:treasury_based</td>\n",
       "      <td>-290.082948</td>\n",
       "      <td>200.243254</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post</td>\n",
       "      <td>-504.194807</td>\n",
       "      <td>427.637145</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post:treasury_based</td>\n",
       "      <td>-504.194807</td>\n",
       "      <td>427.637145</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post</td>\n",
       "      <td>16.028960</td>\n",
       "      <td>74.250187</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post:treasury_based</td>\n",
       "      <td>16.028960</td>\n",
       "      <td>74.250187</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post</td>\n",
       "      <td>-44.809774</td>\n",
       "      <td>123.255579</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post:treasury_based</td>\n",
       "      <td>-44.809774</td>\n",
       "      <td>123.255579</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post</td>\n",
       "      <td>187.743331</td>\n",
       "      <td>146.401332</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post:treasury_based</td>\n",
       "      <td>187.743331</td>\n",
       "      <td>146.401332</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post</td>\n",
       "      <td>213.235326</td>\n",
       "      <td>153.943936</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>[-60,+60] trading days</td>\n",
       "      <td>post:treasury_based</td>\n",
       "      <td>213.235326</td>\n",
       "      <td>153.943936</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         event    spec                  window                 term  \\\n",
       "0   2020-04-01   TOTAL  [-60,+60] trading days                 post   \n",
       "1   2020-04-01   TOTAL  [-60,+60] trading days  post:treasury_based   \n",
       "2   2020-04-01  DIRECT  [-60,+60] trading days                 post   \n",
       "3   2020-04-01  DIRECT  [-60,+60] trading days  post:treasury_based   \n",
       "4   2021-03-19   TOTAL  [-60,+60] trading days                 post   \n",
       "5   2021-03-19   TOTAL  [-60,+60] trading days  post:treasury_based   \n",
       "6   2021-03-19  DIRECT  [-60,+60] trading days                 post   \n",
       "7   2021-03-19  DIRECT  [-60,+60] trading days  post:treasury_based   \n",
       "8   2021-03-31   TOTAL  [-60,+60] trading days                 post   \n",
       "9   2021-03-31   TOTAL  [-60,+60] trading days  post:treasury_based   \n",
       "10  2021-03-31  DIRECT  [-60,+60] trading days                 post   \n",
       "11  2021-03-31  DIRECT  [-60,+60] trading days  post:treasury_based   \n",
       "\n",
       "          coef          se  n_obs  \n",
       "0  -290.082948  200.243254     42  \n",
       "1  -290.082948  200.243254     42  \n",
       "2  -504.194807  427.637145     42  \n",
       "3  -504.194807  427.637145     42  \n",
       "4    16.028960   74.250187     45  \n",
       "5    16.028960   74.250187     45  \n",
       "6   -44.809774  123.255579     45  \n",
       "7   -44.809774  123.255579     45  \n",
       "8   187.743331  146.401332     42  \n",
       "9   187.743331  146.401332     42  \n",
       "10  213.235326  153.943936     42  \n",
       "11  213.235326  153.943936     42  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 2: Event-window jump regressions (pooled) with clear labels\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- patch stargazer globals (pd/np missing in some versions) ---\n",
    "import sys\n",
    "import stargazer.stargazer as _stz\n",
    "import stargazer.translators.statsmodels as _stz_sm\n",
    "\n",
    "def patch_stargazer_globals():\n",
    "    for name, mod in list(sys.modules.items()):\n",
    "        if name and name.startswith(\"stargazer\") and mod is not None:\n",
    "            if not hasattr(mod, \"pd\"):\n",
    "                setattr(mod, \"pd\", pd)\n",
    "            if not hasattr(mod, \"np\"):\n",
    "                setattr(mod, \"np\", np)\n",
    "\n",
    "patch_stargazer_globals()\n",
    "patch_stargazer_globals()\n",
    "\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "# --------- robust selection of W=keep_W models ----------\n",
    "keep_W = 60\n",
    "\n",
    "def is_keep_window(md, keep_W=60):\n",
    "    # Accept several formats in md[\"window\"]\n",
    "    w = md.get(\"window\", \"\")\n",
    "    if isinstance(w, (int, float)):\n",
    "        return int(w) == int(keep_W)\n",
    "    w = str(w)\n",
    "    return (f\"{keep_W}\" in w) and (\"trading\" in w or \"[\" in w or \"W=\" in w or \"window\" in w or w.strip() == str(keep_W))\n",
    "\n",
    "models_keep, meta_keep = [], []\n",
    "for m, md in zip(models, meta):\n",
    "    if is_keep_window(md, keep_W):\n",
    "        models_keep.append(m)\n",
    "        meta_keep.append(md)\n",
    "\n",
    "# Must have at least your 3 events × (TOTAL,DIRECT)\n",
    "if len(models_keep) < len(CONFIG[\"events\"]) * 2:\n",
    "    raise RuntimeError(\n",
    "        f\"Not enough models for Table 2 at W={keep_W}. \"\n",
    "        f\"Have {len(models_keep)}, need at least {len(CONFIG['events'])*2}. \"\n",
    "        \"Check meta['window'] formatting and that regressions ran.\"\n",
    "    )\n",
    "\n",
    "# Sort columns into: event-major, then TOTAL/DIRECT\n",
    "event_order = list(CONFIG[\"events\"])\n",
    "spec_order = {\"TOTAL\": 0, \"DIRECT\": 1}\n",
    "\n",
    "order_idx = sorted(\n",
    "    range(len(models_keep)),\n",
    "    key=lambda i: (\n",
    "        event_order.index(meta_keep[i].get(\"event\")) if meta_keep[i].get(\"event\") in event_order else 999,\n",
    "        spec_order.get(meta_keep[i].get(\"spec\"), 999),\n",
    "    )\n",
    ")\n",
    "models_keep = [models_keep[i] for i in order_idx]\n",
    "meta_keep   = [meta_keep[i]   for i in order_idx]\n",
    "\n",
    "# ---- Stargazer ----\n",
    "sg = Stargazer(models_keep)\n",
    "sg.title(\"Table 2. Event-window jump regressions (DV: |arbitrage spread|, bps)\")\n",
    "sg.show_degrees_of_freedom(False)\n",
    "\n",
    "# Event grouping: 3 events × 2 columns\n",
    "sg.custom_columns(\n",
    "    [\"2020-04-01 Entry\", \"2021-03-19 Ann.\", \"2021-03-31 Exp.\"],\n",
    "    [2, 2, 2]\n",
    ")\n",
    "\n",
    "# Some stargazer versions do NOT support column_labels; add a line instead.\n",
    "try:\n",
    "    sg.column_labels([\"TOTAL\", \"DIRECT\"] * 3)\n",
    "except Exception:\n",
    "    sg.add_line(\"Spec\", [\"TOTAL\", \"DIRECT\"] * 3)\n",
    "\n",
    "sg.rename_covariates({\n",
    "    \"post\": \"Post (t ≥ t0)\",\n",
    "    \"post:treasury_based\": \"Post × TreasuryBased\",\n",
    "    \"treasury_based:post\": \"Post × TreasuryBased\",\n",
    "    \"SOFR\": \"SOFR (bps)\",\n",
    "    \"spr_tgcr\": \"TGCR–SOFR (bps)\",\n",
    "    \"spr_effr\": \"EFFR–SOFR (bps)\",\n",
    "    \"VIX\": \"VIX\",\n",
    "    \"HY_OAS\": \"HY OAS\",\n",
    "    \"BAA10Y\": \"Baa–10y\",\n",
    "    \"issu_7_bil\": \"Issuance 0–7y ($bn)\",\n",
    "    \"issu_14_bil\": \"Issuance 7–14y ($bn)\",\n",
    "    \"issu_30_bil\": \"Issuance 14y+ ($bn)\",\n",
    "})\n",
    "\n",
    "# Keep only key rows (omit FE coefficients)\n",
    "keep = [\"post\", \"post:treasury_based\", \"treasury_based:post\",\n",
    "        \"VIX\",\"HY_OAS\",\"BAA10Y\",\"issu_7_bil\",\"issu_14_bil\",\"issu_30_bil\",\n",
    "        \"SOFR\",\"spr_tgcr\",\"spr_effr\"]\n",
    "\n",
    "sg.covariate_order([k for k in keep if any(k in m.model.exog_names for m in models_keep)])\n",
    "\n",
    "# Notes/lines\n",
    "sg.add_line(\"Window\", [f\"[-{keep_W},+{keep_W}] trading days\"] * len(models_keep))\n",
    "sg.add_line(\"Post definition\", [\"1{t ≥ t0} (includes day 0)\"] * len(models_keep))\n",
    "sg.add_line(\"Series FE\", [\"Yes\"] * len(models_keep))\n",
    "sg.add_line(\"Funding basis controls\", [md.get(\"funding_controls\", \"\") for md in meta_keep])\n",
    "sg.add_line(\"HAC lags (daily)\", [str(CONFIG.get(\"hac_lags_daily\", CONFIG.get(\"hac_lags\", \"\")))] * len(models_keep))\n",
    "sg.add_line(\"Obs.\", [str(int(md.get(\"n_obs\", np.nan))) for md in meta_keep])\n",
    "\n",
    "html_path = run_dir / \"tables\" / \"table2_eventwindow_jumps.html\"\n",
    "html_path.write_text(sg.render_html(), encoding=\"utf-8\")\n",
    "\n",
    "# ---- Compact CSV of key coefficients (handle both interaction name orders) ----\n",
    "rows_out = []\n",
    "for m, md in zip(models_keep, meta_keep):\n",
    "    names = list(m.model.exog_names)\n",
    "\n",
    "    def grab(term):\n",
    "        if term in names:\n",
    "            i = names.index(term)\n",
    "            return float(m.params[i]), float(m.bse[i])\n",
    "        return None\n",
    "\n",
    "    post = grab(\"post\")\n",
    "    inter = grab(\"post:treasury_based\") or grab(\"treasury_based:post\")\n",
    "\n",
    "    if post is not None:\n",
    "        rows_out.append({\n",
    "            \"event\": md.get(\"event\"),\n",
    "            \"spec\": md.get(\"spec\"),\n",
    "            \"window\": md.get(\"window\"),\n",
    "            \"term\": \"post\",\n",
    "            \"coef\": post[0],\n",
    "            \"se\": post[1],\n",
    "            \"n_obs\": int(md.get(\"n_obs\", np.nan)),\n",
    "        })\n",
    "    if inter is not None:\n",
    "        rows_out.append({\n",
    "            \"event\": md.get(\"event\"),\n",
    "            \"spec\": md.get(\"spec\"),\n",
    "            \"window\": md.get(\"window\"),\n",
    "            \"term\": \"post:treasury_based\",\n",
    "            \"coef\": inter[0],\n",
    "            \"se\": inter[1],\n",
    "            \"n_obs\": int(md.get(\"n_obs\", np.nan)),\n",
    "        })\n",
    "\n",
    "table2_key = pd.DataFrame(rows_out)\n",
    "table2_key.to_csv(run_dir / \"tables\" / \"table2_key_coefs.csv\", index=False)\n",
    "table2_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec</th>\n",
       "      <th>term</th>\n",
       "      <th>coef</th>\n",
       "      <th>se</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>relief</td>\n",
       "      <td>-539.197339</td>\n",
       "      <td>83.794174</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>relief:treasury_based</td>\n",
       "      <td>-539.197339</td>\n",
       "      <td>83.794174</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIRECT</td>\n",
       "      <td>relief</td>\n",
       "      <td>-136.062913</td>\n",
       "      <td>90.050280</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIRECT</td>\n",
       "      <td>relief:treasury_based</td>\n",
       "      <td>-136.062913</td>\n",
       "      <td>90.050280</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     spec                   term        coef         se    N\n",
       "0   TOTAL                 relief -539.197339  83.794174  273\n",
       "1   TOTAL  relief:treasury_based -539.197339  83.794174  273\n",
       "2  DIRECT                 relief -136.062913  90.050280  273\n",
       "3  DIRECT  relief:treasury_based -136.062913  90.050280  273"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 3: Relief-period regression (full-sample indicator; answers “during the exclusion period”)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# pooled across all series; series FE; TOTAL vs DIRECT\n",
    "relief_models = []\n",
    "relief_meta = []\n",
    "rows = []\n",
    "\n",
    "for spec, controls_set in [(\"TOTAL\", CONFIG[\"total_controls\"]), (\"DIRECT\", CONFIG[\"direct_controls\"])]:\n",
    "    robust, reg = run_relief_reg(panel_long, y_col=\"y_abs_bps\", controls=controls_set, fe_col=\"series_id\", interact_treasury=True)\n",
    "    relief_models.append(robust)\n",
    "    relief_meta.append({\"spec\": spec, \"funding_controls\": \"Yes\" if spec==\"DIRECT\" else \"No\", \"n_obs\": int(robust.nobs)})\n",
    "\n",
    "    for term in [\"relief\",\"relief:treasury_based\"]:\n",
    "        if term in robust.model.exog_names:\n",
    "            i = robust.model.exog_names.index(term)\n",
    "            rows.append({\"spec\": spec, \"term\": term, \"coef\": float(robust.params[i]), \"se\": float(robust.bse[i]), \"N\": int(robust.nobs)})\n",
    "\n",
    "table3 = pd.DataFrame(rows)\n",
    "table3.to_csv(run_dir / \"tables\" / \"table3_relief_regression.csv\", index=False)\n",
    "table3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>tenor</th>\n",
       "      <th>N_days</th>\n",
       "      <th>mean_absW</th>\n",
       "      <th>median_absW</th>\n",
       "      <th>share_absW_le_5</th>\n",
       "      <th>share_absW_le_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>817.458123</td>\n",
       "      <td>680.866667</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>2</td>\n",
       "      <td>251</td>\n",
       "      <td>755.623904</td>\n",
       "      <td>709.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ust_spot_fut</td>\n",
       "      <td>5</td>\n",
       "      <td>251</td>\n",
       "      <td>767.842010</td>\n",
       "      <td>699.255556</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       strategy tenor  N_days   mean_absW  median_absW  share_absW_le_5  \\\n",
       "0  ust_spot_fut    10     251  817.458123   680.866667         0.003984   \n",
       "1  ust_spot_fut     2     251  755.623904   709.166667         0.000000   \n",
       "2  ust_spot_fut     5     251  767.842010   699.255556         0.003984   \n",
       "\n",
       "   share_absW_le_10  \n",
       "0          0.003984  \n",
       "1          0.000000  \n",
       "2          0.007968  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 4: “Near-zero” summary during relief (by strategy × tenor)\n",
    "\n",
    "import pandas as pd\n",
    "deltas = CONFIG[\"near_zero_deltas\"]\n",
    "\n",
    "relief = panel_long[(panel_long[\"date\"] >= \"2020-04-01\") & (panel_long[\"date\"] <= \"2021-03-31\")].copy()\n",
    "\n",
    "rows = []\n",
    "for (strategy, tenor), g in relief.groupby([\"strategy\",\"tenor\"]):\n",
    "    ya = pd.to_numeric(g[\"y_abs_bps\"], errors=\"coerce\")\n",
    "    if ya.dropna().empty:\n",
    "        continue\n",
    "    row = {\n",
    "        \"strategy\": str(strategy),\n",
    "        \"tenor\": str(tenor),\n",
    "        \"N_days\": int(ya.notna().sum()),\n",
    "        \"mean_absW\": float(ya.mean()),\n",
    "        \"median_absW\": float(ya.median()),\n",
    "    }\n",
    "    for d0 in deltas:\n",
    "        row[f\"share_absW_le_{int(d0)}\"] = float((ya <= d0).mean())\n",
    "    rows.append(row)\n",
    "\n",
    "table4 = pd.DataFrame(rows).sort_values([\"strategy\",\"tenor\"])\n",
    "table4.to_csv(run_dir / \"tables\" / \"table4_nearzero_relief.csv\", index=False)\n",
    "table4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Layer 2 executed. pooled_n=156; strategies=['ust_spot_fut']\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer 2 (weekly): changes in spreads, with strategy-by-strategy and pooled panels; controls in bps\n",
    "\n",
    "layer2_note = \"\"\n",
    "try:\n",
    "    pd_long = load_any_table(resolve_dataset_path(\"primary_dealer_stats_ofr_stfm_nypd_long\", expected_dir=repo_root / \"data\" / \"raw\" / \"event_inputs\"))\n",
    "    bank = load_any_table(resolve_dataset_path(\"bank_exposure_y9c_agg_daily\", expected_dir=repo_root / \"data\" / \"raw\" / \"event_inputs\"))\n",
    "\n",
    "    pd_long[\"date\"] = pd.to_datetime(pd_long[\"date\"], errors=\"coerce\")\n",
    "    bank[\"date\"] = pd.to_datetime(bank[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    # dealer utilization proxy (weekly)\n",
    "    util_w = pd_long.pivot_table(index=\"date\", columns=\"mnemonic\", values=\"value\", aggfunc=\"mean\").resample(\"W-FRI\").mean()\n",
    "    util_w[\"utilization_index\"] = util_w.sum(axis=1, min_count=1)\n",
    "    util_w[\"utilization_lag1w\"] = util_w[\"utilization_index\"].shift(1)\n",
    "\n",
    "    # bank exposure proxy (weekly)\n",
    "    if \"agg_exempt_share\" not in bank.columns:\n",
    "        raise KeyError(\"bank_exposure_y9c_agg_daily missing 'agg_exempt_share'\")\n",
    "    bank_w = bank.set_index(\"date\").resample(\"W-FRI\").mean()[[\"agg_exempt_share\"]]\n",
    "\n",
    "    # weekly series panel: mean within week per series_id, then first-diff\n",
    "    pl = panel_long.copy()\n",
    "    pl[\"date\"] = pd.to_datetime(pl[\"date\"], errors=\"coerce\")\n",
    "    pl = pl.dropna(subset=[\"date\"])\n",
    "    pl = pl.set_index(\"date\")\n",
    "\n",
    "    y_w = (pl.groupby(\"series_id\")[\"y_abs_bps\"].resample(\"W-FRI\").mean().rename(\"y\").reset_index())\n",
    "    # add strategy and treasury_based labels (time-invariant per series)\n",
    "    labels = panel_long[[\"series_id\",\"strategy\",\"tenor\",\"treasury_based\"]].drop_duplicates()\n",
    "    y_w = y_w.merge(labels, on=\"series_id\", how=\"left\")\n",
    "\n",
    "    # weekly controls (levels), then differences to match ΔW design\n",
    "    ctrl_cols = [c for c in CONFIG[\"direct_controls\"] if c in pl.columns]\n",
    "    c_w = pl[ctrl_cols].resample(\"W-FRI\").mean()\n",
    "\n",
    "    # funding controls already in bps from controls builder; keep in bps\n",
    "    # build per-week panel by joining on date\n",
    "    y_w = y_w.set_index(\"date\")\n",
    "    mech = y_w.join([bank_w, util_w[[\"utilization_lag1w\"]], c_w], how=\"inner\").dropna()\n",
    "\n",
    "    # relief indicator (weekly, inclusive)\n",
    "    mech[\"relief\"] = ((mech.index >= \"2020-04-01\") & (mech.index <= \"2021-03-31\")).astype(int)\n",
    "\n",
    "    # dependent variable: weekly change in |spread|\n",
    "    mech[\"dy\"] = mech.groupby(\"series_id\")[\"y\"].diff()\n",
    "\n",
    "    # controls as weekly changes (to match ΔW text)\n",
    "    for c in ctrl_cols:\n",
    "        mech[f\"d_{c}\"] = mech[c].diff()\n",
    "\n",
    "    # z-scores\n",
    "    ex_std = mech[\"agg_exempt_share\"].std()\n",
    "    util_std = mech[\"utilization_lag1w\"].std()\n",
    "    mech[\"z_exempt\"] = (mech[\"agg_exempt_share\"] - mech[\"agg_exempt_share\"].mean()) / (ex_std if ex_std and ex_std > 0 else 1.0)\n",
    "    mech[\"z_util_l1\"] = (mech[\"utilization_lag1w\"] - mech[\"utilization_lag1w\"].mean()) / (util_std if util_std and util_std > 0 else 1.0)\n",
    "\n",
    "    mech[\"relief_x_exempt\"] = mech[\"relief\"] * mech[\"z_exempt\"]\n",
    "    mech[\"relief_x_util\"] = mech[\"relief\"] * mech[\"z_util_l1\"]\n",
    "\n",
    "    # pooled panel with series FE + treasury_based interactions\n",
    "    base_x = [\"relief\",\"relief_x_exempt\",\"relief_x_util\"]\n",
    "    xcols = base_x + [f\"d_{c}\" for c in ctrl_cols]\n",
    "    # interactions to align with cross-strategy mechanism claim\n",
    "    mech[\"relief_x_treas\"] = mech[\"relief\"] * mech[\"treasury_based\"].astype(int)\n",
    "    mech[\"relief_x_exempt_x_treas\"] = mech[\"relief_x_exempt\"] * mech[\"treasury_based\"].astype(int)\n",
    "    mech[\"relief_x_util_x_treas\"] = mech[\"relief_x_util\"] * mech[\"treasury_based\"].astype(int)\n",
    "    xcols_int = xcols + [\"relief_x_treas\",\"relief_x_exempt_x_treas\",\"relief_x_util_x_treas\"]\n",
    "\n",
    "    reg = mech.dropna(subset=[\"dy\", *xcols_int]).copy()\n",
    "    reg = sanitize_for_patsy(reg, category_cols=[\"series_id\"])\n",
    "\n",
    "    X = sm.add_constant(reg[xcols_int], has_constant=\"add\")\n",
    "    pooled = sm.OLS(reg[\"dy\"], X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": CONFIG[\"hac_lags_weekly\"]})\n",
    "    pooled_out = pd.DataFrame({\"term\": pooled.params.index, \"coef\": pooled.params.values, \"se\": pooled.bse.values})\n",
    "    pooled_out.to_csv(run_dir / \"tables\" / \"layer2_weekly_changes_pooled.csv\", index=False)\n",
    "\n",
    "    # strategy-by-strategy regressions (same xcols without treasury interactions)\n",
    "    by_rows = []\n",
    "    for strategy in sorted(reg[\"strategy\"].astype(str).unique().tolist()):\n",
    "        r = reg[reg[\"strategy\"].astype(str) == strategy].copy()\n",
    "        if r.shape[0] < 20:\n",
    "            continue\n",
    "        Xs = sm.add_constant(r[xcols], has_constant=\"add\")\n",
    "        res = sm.OLS(r[\"dy\"], Xs).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": CONFIG[\"hac_lags_weekly\"]})\n",
    "        for term in res.params.index:\n",
    "            by_rows.append({\"strategy\": strategy, \"term\": term, \"coef\": float(res.params[term]), \"se\": float(res.bse[term]), \"N\": int(res.nobs)})\n",
    "\n",
    "    by_out = pd.DataFrame(by_rows)\n",
    "    by_out.to_csv(run_dir / \"tables\" / \"layer2_weekly_changes_by_strategy.csv\", index=False)\n",
    "\n",
    "    layer2_note = f\"Layer 2 executed. pooled_n={int(pooled.nobs)}; strategies={sorted(reg['strategy'].astype(str).unique().tolist())}\"\n",
    "except Exception as exc:  # noqa: BLE001\n",
    "    layer2_note = f\"Layer 2 skipped gracefully: {exc}\"\n",
    "\n",
    "layer2_note\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "408190e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 7\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 12, but rank is 7\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 12, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 6\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "c:\\ProgramData\\anaconda3\\envs\\risk\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 12, but rank is 6\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/Owner/Box/Winter26/slr_bucket/outputs/summary_pipeline/20260228_203643_01492bfdea93/tables/regression_table.tex')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Stargazer LaTeX export (same models/style as HTML) ---\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Patch broken stargazer installs that reference pd/np without importing them\n",
    "def patch_stargazer_globals():\n",
    "    for name, mod in list(sys.modules.items()):\n",
    "        if name and name.startswith(\"stargazer\") and mod is not None:\n",
    "            if not hasattr(mod, \"pd\"):\n",
    "                setattr(mod, \"pd\", pd)\n",
    "            if not hasattr(mod, \"np\"):\n",
    "                setattr(mod, \"np\", np)\n",
    "\n",
    "patch_stargazer_globals()\n",
    "\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "assert len(models) > 0, \"No models were estimated; cannot export Stargazer LaTeX table.\"\n",
    "\n",
    "tex_path = run_dir / \"tables\" / \"regression_table.tex\"\n",
    "\n",
    "sg = Stargazer(models)\n",
    "sg.title(\"Pooled Jump Regressions (HAC SE)\")\n",
    "sg.show_degrees_of_freedom(False)\n",
    "\n",
    "# If your HTML cell uses any additional formatting calls (custom columns, covariate order, etc.),\n",
    "# mirror them here as well.\n",
    "\n",
    "# Generate LaTeX (method name varies across stargazer versions)\n",
    "if hasattr(sg, \"render_latex\"):\n",
    "    tex = sg.render_latex()\n",
    "elif hasattr(sg, \"render_latex_table\"):\n",
    "    tex = sg.render_latex_table()\n",
    "else:\n",
    "    raise AttributeError(\"Stargazer object has no LaTeX render method (render_latex / render_latex_table).\")\n",
    "\n",
    "tex_path.write_text(tex, encoding=\"utf-8\")\n",
    "\n",
    "tex_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
